---
title: |
  | å…³äºå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£
  | è‡ªç„¶è¯­è¨€åˆ†æä½¿ç”¨ä¸€äº›æƒ³æ³•
subtitle: "æ–°é—»ä¼ æ’­å­¦å®šé‡ç ”ç©¶æ–¹æ³•ä½“ç³»å»ºè®¾ç ”è®¨ä¼š"
date: "2025-06-23"
author: "èƒ¡æ‚¦"
institute: "æ¸…åå¤§å­¦ç¤¾ä¼šç§‘å­¦å­¦é™¢"

bibliography: pre_css.bib

format: 
  revealjs:
    css: https://www.drhuyue.site/slides_gh/css/style_basic.css
    theme: ../../css/goldenBlack.scss
    slide-number: true
    filters: [appExclusion.lua] # not count appendices into page number
    incremental: false
    preview-links: true # open an iframe for a link
    link-external-newwindow: true
    self-contained: false
    chalkboard: false # allwoing chalk board B, notes canvas C
    # callout-icon: false
    show-slide-number: all # `speaker` only print in pdf, `all` shows all the time
    title-slide-attributes:
      data-background-image: https://gitlab.com/sammo3182/backup/raw/85b3c1ad4b459d7a9f901f124b936428eda5fcaf/logo_THPS.png?inline=true
      data-background-size: 250px   
      data-background-position: top 10% right 5%
    default-image-extension: png
revealjs-plugins:
  - spotlight
lightbox: 
  match: auto
  effect: fade
spotlight:
  size: 50
  presentingCursor: default
  toggleSpotlightOnMouseDown: false
  spotlightOnKeyPressAndHold: 73 # keycode for "i"

execute: 
    echo: true
editor_options: 
    chunk_output_type: console
editor: 
    render-on-save: true
---

```{r}
#| include: false
#| label: setup

library(pacman)

p_load(
    "icons",
    "tidyverse"
)

# Functions preload
set.seed(313)
```

## é—®é¢˜

::: {style="text-align:center; margin-top: 1em"}

å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£ï¼Œè¿˜éœ€è¦ï¼ˆç³»ç»Ÿï¼‰å­¦ä¹ ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰ç ”ç©¶æ–¹æ³•å—ï¼Ÿ

- ä¸»ä½“ï¼š[ç ”ç©¶è€…]{.red}è¿˜éœ€è¦å­¦å—ï¼Ÿå­¦ç”Ÿè¿˜éœ€è¦å­¦å—ï¼Ÿ
- å†…å®¹ï¼šè¦å­¦NLPå—ï¼Ÿè¦å­¦[ç»Ÿè®¡]{.red}å—ï¼Ÿè¦å­¦ç¼–ç¨‹å—ï¼Ÿ
- æ–¹å¼ï¼šï¼ˆéå¾—è¦çš„è¯ï¼‰[ä»€ä¹ˆæ—¶å€™]{.red}ä½¿ç”¨ï¼Ÿæ€ä¹ˆä½¿ç”¨ï¼Ÿ

:::


## ç¼˜èµ·

::: {style="text-align:center"}

[çº¯]{.red}æ–‡ç§‘ç”Ÿä¸Šäº†â€œå®šé‡â€çš„èˆ¹

:::

:::: {.columns}

::: {.column .fragment width="50%"}

![@Hu2020a](https://drhuyue.site:10002/sammo3182/figure/text_democracy1991.png){.fragment fig-align="center" height=500}

::: {.notes}

- ç”±surveyèµ·å®¶çš„ç ”ç©¶è¿›è·¯
- æ”¿æ²»å¿ƒç†å­¦ + æ”¿æ²»è¯­è¨€å­¦
- è¾ƒæ—©å°†STMå¼•å…¥ä¸­å›½æ”¿æ²»å­¦ç ”ç©¶

:::

:::

::: {.column .fragment width="50%"}


![](https://drhuyue.site:10002/sammo3182/figure/2023_rClass.png){.fragment fig-align="center" height=500}

::: {.notes}

- åŸºç¡€æ–¹æ³•è¯¾ç¨‹ï¼ˆæ¦‚ç‡è®º &rarr; å›å½’ï¼‰
- å¤§æ•°æ®è¯¾ç¨‹
- ç¼–ç¨‹å·¥ä½œåŠ

:::

:::

::::



## å¤§è¯­è¨€æ¨¡å‹æ¥äº†â€¦â€¦

::::{.overlay-container}

::: {.overlay-text}

- å‰å…†ï¼šâ€œè®¡ç®—ç¤¾ä¼šç§‘å­¦æ—¶ä»£â€ &rarr; è¯é¢‘åˆ†æè½ä¼äº†
- å¤§è¯­è¨€æ¨¡å‹ï¼šäººç±»è¯­è¨€è¢«ç ´è§£ &rarr; è‡ªç„¶è¯­è¨€åˆ†æ/â€œæœºå™¨å­¦ä¹ â€è½ä¼äº†

:::

::: {.overlay-image .fragment}

![@YangEtAl2024a](https://drhuyue.site:10002/sammo3182/figure/css_llmTree.jpg){fig-align="center" height=600}

:::

::: {.overlay-text-over .fragment}

::: {.callout-note}

## ä¸ç¾å›½çŸ¥åæ”¿æ²»å­¦æ•™æˆã€åæ ¡åšå£«ã€å¤§å‚åˆ†æå¸ˆçš„äº¤æµ

:::: {.columns}

::: {.column .incremental width="50%"}

- *æˆ‘*ï¼šå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£ï¼Œæ˜¯ä¸æ˜¯ä¸ç”¨å­¦æ–‡æœ¬åˆ†æäº†ï¼Ÿ
- *ä¸“å®¶*ï¼šèƒ½ç”¨å¤§æ¨¡å‹åšçš„å°±ç”¨å¤§æ¨¡å‹å§ã€‚
- *æˆ‘*ï¼šé‚£å­¦ç”Ÿä»¬æ˜¯ä¸æ˜¯ä¹Ÿä¸ç”¨å­¦ä¹ æ–¹æ³•äº†å—ï¼Ÿ
- *ä¸“å®¶*ï¼šå°±æ˜¯ç”¨ä¸€ä¸‹å¯ä»¥ä¸å­¦ï¼Œè¦æƒ³æ·±å…¥ç ”ç©¶çš„è¯ï¼Œè¿˜æ˜¯å¾—å­¦ä¸€äº›ã€‚
- *æˆ‘*ï¼šâ€œæ·±å…¥ç ”ç©¶â€ä»€ä¹ˆï¼Ÿ
- *ä¸“å®¶*ï¼šç†è§£æ–¹æ³•åº”ç”¨çš„åŸç†å‘€ã€æ­£ç¡®ä½¿ç”¨å•Šä¹‹ç±»çš„ã€‚
- *æˆ‘*ï¼šä¸æ˜¯å¯ä»¥é—®å¤§è¯­è¨€æ¨¡å‹ä¹ˆï¼Ÿè€Œä¸”ç»™çš„ç­”æ¡ˆè¶Šæ¥è¶Šå‡†ç¡®äº†ã€‚
- *ä¸“å®¶*ï¼šç¡®å®ã€‚

:::

::: {.column .incremental width="50%"}

- *æˆ‘*ï¼šçœä¸‹ç²¾åŠ›æ¥ï¼Œè¿˜å¯ä»¥å¤šè¯»ç†è®ºã€å¤šçœ‹è®ºæ–‡ã€‚
- *ä¸“å®¶*ï¼šä»–ä»¬ä¹Ÿä¸çœ‹å•Šâ€¦â€¦
- *æˆ‘*ï¼šæ˜¯ä¸æ˜¯è¿ç¼–ç¨‹ä¹Ÿä¸ç”¨å­¦äº†ï¼Ÿ
- *ä¸“å®¶*ï¼šç°åœ¨LLMè¿˜ä¸è¡Œï¼Œä¼šå‡ºå¾ˆå¤šbugã€‚
- *æˆ‘*ï¼šè·‘ä¸é€šå¯ä»¥å†è®©LLM debugå•Šã€‚è€Œä¸”ï¼Œvibe codingåœ¨é£é€Ÿå‘å±•å‘€ï¼è‚¯å®šä¼šè¶Šæ¥è¶Šå‡†çš„ã€‚
- *ä¸“å®¶*ï¼šç¡®å®ï¼Œ90%çš„ç¨‹åºéƒ½ä¸æ˜¯è‡ªå·±å†™çš„äº†ã€‚
- *æˆ‘*ï¼šé‚£æˆ‘çš„ç¼–ç¨‹åŸ¹è®­ç­æ˜¯ä¸æ˜¯å¯ä»¥ä¸å¼€äº†â€¦â€¦
- *ä¸“å®¶*ï¼šğŸ™‚ï¼ˆå°´å°¬è€Œåˆä¸å¤±ç¤¼è²Œçš„å¾®ç¬‘ï¼‰

:::

::::

:::

:::

::::


## æƒ³æ³•1ï¼šå­¦ä¹ ä¸»ä½“

:::: {.columns}

::: {.column .incremental width="50%"}

- å­¦è€…è¿˜è¦ä¸è¦å…³æ³¨æ–¹æ³•ï¼š
  - è¿˜æ˜¯å¾—å…³æ³¨
  - è¿˜æ˜¯å¾—å…³æ³¨

::: {.notes}

- ä»æ–¹æ³•è§’åº¦ï¼šå¼¥è¡¥äººåŠ›
- ä»äº‹ä¸šè§’åº¦ï¼šåŸ¹å…»å­¦ç”Ÿ

:::

:::

::: {.column .incremental width="50%"}

- å­¦ç”Ÿè¿˜è¦ä¸è¦å­¦ä¹ æ–¹æ³•ï¼š
  - ç³»ç»Ÿå­¦ä¹ 
  - èƒ½åŠ›è®­ç»ƒ
  - æƒåŠ›å…³ç³»

::: {.notes}

- ç³»ç»Ÿå­¦ä¹  vs. ç¢ç‰‡åŒ–å­¦ä¹ 
- èƒ½åŠ›è®­ç»ƒ vs. çŸ¥è¯†ç§¯ç´¯
- ä¸»åŠ¨æƒåœ¨è°çš„æ‰‹é‡Œ

:::

:::

::::

## æƒ³æ³•2ï¼šå­¦ä¹ å†…å®¹

â€œæœ€å¥½åƒäººä¸€æ ·è¯»â€ [& â€œèƒ½è·‘å°±è¡Œâ€]{.fragment}

::: {.notes}

- è¯­è¨€çš„ç»Ÿè®¡æ€§è§„å¾‹
- Function words
- Linguistic psychology

:::


::: {.r-stack .fragment}

```{r}
#| label: llmCoding
#| eval: false

##è¯´æ˜
#8-170è¡Œå±äºçˆ¬å–æ•°æ®çš„ç¯èŠ‚
#180-321 æœç´¢data scrapingåŒ…åŠç›¸å…³ä¿¡æ¯
#325-474 æœç´¢data cleaningåŒ…åŠç›¸å…³ä¿¡æ¯
#478-632 æœç´¢data transformationåŒ…ä»¥åŠç›¸å…³ä¿¡æ¯

library(rvest)
library(httr)
library(dplyr)
library(purrr)
library(progress)
library(cli)

user_agent <- "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
delay_seconds <- 0.5

# çˆ¬å–æ‰€æœ‰RåŒ…çš„å…ƒä¿¡æ¯
scrape_cran_meta_descriptions <- function(max_packages = NULL) {
  # è·å–åŒ…çš„é“¾æ¥
  cli_alert_info("æ­£åœ¨è·å–CRANåŒ…åˆ—è¡¨...")
  main_url <- "https://cran.r-project.org/web/packages/available_packages_by_date.html"

  # å‘é€HTTPè¯·æ±‚
  response <- GET(main_url, user_agent(user_agent))
  if (http_status(response)$category != "Success") {
    cli_alert_danger("æ— æ³•è·å–ä¸»é¡µé¢: {http_status(response)$message}")
    return(NULL)
  }

  # è§£æHTMLå†…å®¹
  html_content <- content(response, as = "text")
  page <- read_html(html_content)

  # æå–è¡¨æ ¼ä¸­çš„æ‰€æœ‰è¡Œ
  rows <- page %>% html_nodes("table tr")

  # æå–åŒ…åå’Œé“¾æ¥(è·³è¿‡è¡¨å¤´)
  package_links <- map_dfr(rows[-1], function(row) {
    cols <- html_nodes(row, "td")
    if (length(cols) >= 2) {
      link <- html_node(cols[2], "a")
      if (!is.na(link)) {
        href <- html_attr(link, "href")
        name <- html_text(link) %>% trimws()

        # æ„å»ºURL
        full_url <- paste0(
          "https://cran.r-project.org",
          sub("^\\.\\./(\\.\\./)?", "/", href)
        )

        return(data.frame(
          package = name,
          url = full_url,
          stringsAsFactors = FALSE
        ))
      }
    }
    return(NULL)
  })

  #
  if (!is.null(max_packages)) {
    package_links <- head(package_links, max_packages)
    cli_alert_info("æµ‹è¯•æ¨¡å¼ï¼šåªçˆ¬å–å‰ {max_packages} ä¸ªåŒ…")
  }

  cli_alert_success("å‡†å¤‡çˆ¬å– {nrow(package_links)} ä¸ªRåŒ…çš„å…ƒæè¿°ä¿¡æ¯")

  # éå†æ¯ä¸ªåŒ…è·å–å…ƒä¿¡æ¯
  cli_alert_info("å¼€å§‹çˆ¬å–å…ƒæè¿°ä¿¡æ¯...")

  # åˆ›å»ºè¿›åº¦æ¡
  pb <- progress_bar$new(
    format = "[:bar] :percent | å·²å¤„ç†: :current / :total | å‰©ä½™: :eta",
    total = nrow(package_links),
    clear = FALSE
  )

  # å®šä¹‰æŠ“å–å•ä¸ªåŒ…æè¿°çš„å‡½æ•°
  scrape_package_meta <- function(url, package_name) {
    pb$tick()
    Sys.sleep(delay_seconds)

    tryCatch(
      {
        # å‘é€HTTPè¯·æ±‚
        pkg_response <- GET(url, user_agent(user_agent))
        if (http_status(pkg_response)$category != "Success") {
          return(data.frame(
            package = package_name,
            meta_description = paste(
              "HTTPé”™è¯¯:",
              http_status(pkg_response)$message
            ),
            stringsAsFactors = FALSE
          ))
        }

        # è§£æHTMLå†…å®¹
        pkg_html <- content(pkg_response, as = "text")
        pkg_page <- read_html(pkg_html)

        # æå–<head>ä¸­çš„<meta property="og:description">å†…å®¹
        meta_description <- pkg_page %>%
          html_node('head meta[property="og:description"]') %>%
          html_attr("content")

        # å¦‚æœæ‰¾åˆ°æè¿°ï¼Œè¿›è¡Œæ¸…ç†
        if (!is.na(meta_description)) {
          # æ¸…ç†HTMLå®ä½“å’Œå¤šä½™ç©ºæ ¼
          meta_description <- gsub("&amp;", "&", meta_description)
          meta_description <- gsub("&lt;", "<", meta_description)
          meta_description <- gsub("&gt;", ">", meta_description)
          meta_description <- gsub("\\s+", " ", meta_description) %>% trimws()

          return(data.frame(
            package = package_name,
            meta_description = meta_description,
            stringsAsFactors = FALSE
          ))
        }

        # å¦‚æœæ‰¾ä¸åˆ°æè¿°ï¼Œå°è¯•æå–å¸¸è§„æè¿°
        cli_alert_warning(
          "åŒ… {package_name} æœªæ‰¾åˆ°og:descriptionå…ƒæ ‡ç­¾ï¼Œå°è¯•æå–å¸¸è§„æè¿°"
        )

        # å°è¯•ä»è¡¨æ ¼ä¸­æå–æè¿°
        description_row <- pkg_page %>%
          html_nodes("tr") %>%
          keep(~ html_text(html_node(.x, "td:nth-child(1)")) == "Description:")

        if (length(description_row) > 0) {
          description <- description_row[[1]] %>%
            html_node("td:nth-child(2)") %>%
            html_text() %>%
            gsub("\\s+", " ", .) %>%
            trimws()

          return(data.frame(
            package = package_name,
            meta_description = description,
            stringsAsFactors = FALSE
          ))
        }

        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›æœªæ‰¾åˆ°
        return(data.frame(
          package = package_name,
          meta_description = "Description not found",
          stringsAsFactors = FALSE
        ))
      },
      error = function(e) {
        return(data.frame(
          package = package_name,
          meta_description = paste("é”™è¯¯:", conditionMessage(e)),
          stringsAsFactors = FALSE
        ))
      }
    )
  }

  # ä½¿ç”¨mapå®‰å…¨åœ°éå†æ‰€æœ‰åŒ…
  results <- map2_dfr(
    package_links$url,
    package_links$package,
    scrape_package_meta
  )

  # ç»Ÿè®¡ç»“æœ
  success_count <- sum(
    results$meta_description != "Description not found" &
      !grepl("é”™è¯¯:|HTTPé”™è¯¯", results$meta_description)
  )

  cli_alert_success("æˆåŠŸçˆ¬å– {success_count} ä¸ªåŒ…çš„å…ƒæè¿°ä¿¡æ¯")

  # ä¿å­˜ç»“æœåˆ°CSV
  output_file <- "cran_package_meta_descriptions.csv"
  write.csv(results, output_file, row.names = FALSE, fileEncoding = "UTF-8")
  cli_alert_success("ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

  return(results)
}


# teståªçˆ¬å–å‰5ä¸ªåŒ…
results_sample <- scrape_cran_meta_descriptions(max_packages = 5)

# æŸ¥çœ‹ç»“æœ
print(results_sample)

# å®Œæ•´çˆ¬å–
all_results <- scrape_cran_meta_descriptions()

data <- read.csv("cran_package_meta_descriptions.csv", nrows = 100)
View(data)

library(readr)
data <- read_csv("cran_package_meta_descriptions.csv")

#åˆ†åˆ«åŒ¹é…å…³é”®è¯

library(dplyr)
library(stringr)
library(openxlsx)

##data scraping

descriptions_df <- read.csv(
  "cran_package_meta_descriptions.csv",
  stringsAsFactors = FALSE,
  fileEncoding = "UTF-8"
)
###åŒ¹é…å…³é”®è¯
scraping_keywords <- c(
  "scrap",
  "crawl",
  "API",
  "extract",
  "harvest",
  "gather",
  "retrieve",
  "collect"
)

###å»ºç«‹â€œæˆ–â€å…³ç³»
pattern <- paste0("\\b(", paste(scraping_keywords, collapse = "|"), ")\\b")
pattern <- regex(pattern, ignore_case = TRUE)

###ç­›é€‰åŒ…å«å…³é”®è¯çš„åŒ…
scraping_packages <- descriptions_df %>%

  filter(
    !str_detect(meta_description, "é”™è¯¯:|HTTPé”™è¯¯|Description not found")
  ) %>%

  mutate(
    is_scraping = str_detect(meta_description, pattern),

    matched_keywords = str_extract_all(meta_description, pattern) %>%
      map_chr(~ paste(unique(.x), collapse = ", "))
  ) %>%

  filter(is_scraping) %>%

  select(package, meta_description, matched_keywords) %>%

  arrange(package)

###æ‰“å°å‰10
head(scraping_packages, 10)

write.xlsx(scraping_packages, "scraping_packages.xlsx")

cat("å‘ç°", nrow(scraping_packages), "ä¸ªä¸æ•°æ®æŠ“å–ç›¸å…³çš„RåŒ…\n")

###æ·»åŠ åŒ…é“¾æ¥
scraping_packages <- scraping_packages %>%
  mutate(
    cran_link = paste0(
      "https://cran.r-project.org/web/packages/",
      package,
      "/index.html"
    )
  )

###ä¿å­˜å¸¦é“¾æ¥çš„ç»“æœ
write.xlsx(scraping_packages, "data_scraping_packages_with_links.xlsx")

###æ·»åŠ ä¸‹è½½é‡ä¿¡æ¯
library(cranlogs)

###åˆ†æ‰¹å¤„ç†50
batch_size <- 50
batches <- split(
  scraping_packages$package,
  ceiling(seq_along(scraping_packages$package) / batch_size)
)

from_date <- Sys.Date() - 90
to_date <- Sys.Date()


download_stats_list <- map(batches, function(batch) {
  Sys.sleep(1)
  cran_downloads(
    packages = batch,
    from = from_date,
    to = to_date
  )
})

###åˆå¹¶åˆ†æ‰¹ä¸‹è½½çš„æ•°æ®
download_stats <- bind_rows(download_stats_list)

download_summary <- download_stats %>%
  group_by(package) %>%
  summarise(total_downloads = sum(count))

scraping_packages <- scraping_packages %>%
  left_join(download_summary, by = "package") %>%
  arrange(desc(total_downloads))

print(scraping_packages)

write.xlsx(scraping_packages, "data_scraping_packages_with_links_rank.xlsx")

###æ·»åŠ ä½œè€…ä¿¡æ¯

get_authors_from_cran <- function(package_name) {
  tryCatch(
    {
      ###æ„å»ºDESCRIPTIONæ–‡ä»¶URL
      desc_url <- paste0(
        "https://cran.r-project.org/web/packages/",
        package_name,
        "/DESCRIPTION"
      )

      ###å‘é€HTTPè¯·æ±‚
      response <- GET(desc_url, user_agent("Mozilla/5.0"))
      if (http_status(response)$category != "Success") {
        return(list(author = NA, maintainer = NA))
      }

      ###è§£æDESCRIPTIONå†…å®¹
      desc_content <- content(response, as = "text")

      ###æå–ä½œè€…å’Œç»´æŠ¤è€…ä¿¡æ¯
      author <- if (grepl("Author:", desc_content)) {
        sub(".*Author:([^\n]+).*", "\\1", desc_content) %>% trimws()
      } else {
        NA_character_
      }

      maintainer <- if (grepl("Maintainer:", desc_content)) {
        sub(".*Maintainer:([^\n]+).*", "\\1", desc_content) %>% trimws()
      } else {
        NA_character_
      }

      return(list(author = author, maintainer = maintainer))
    },
    error = function(e) {
      return(list(author = NA, maintainer = NA))
    }
  )
}

###ä¸ºæ¯ä¸ªåŒ…è·å–ä½œè€…ä¿¡æ¯
if (
  !"author" %in% colnames(scraping_packages) ||
    all(is.na(scraping_packages$author))
) {
  ###åˆ›å»ºè¿›åº¦æ¡
  pb <- progress_bar$new(
    format = "è·å–ä½œè€…ä¿¡æ¯ [:bar] :percent | å·²å¤„ç†: :current / :total | å‰©ä½™: :eta",
    total = nrow(scraping_packages),
    clear = FALSE
  )

  ###è·å–ä½œè€…ä¿¡æ¯
  author_info <- map(scraping_packages$package, function(pkg) {
    pb$tick()
    Sys.sleep(0.3) # ç¤¼è²Œæ€§å»¶æ—¶
    get_authors_from_cran(pkg)
  })

  ###æ·»åŠ ä½œè€…ä¿¡æ¯åˆ°æ•°æ®æ¡†
  scraping_packages$author <- map_chr(author_info, ~ .x$author)
  scraping_packages$maintainer <- map_chr(author_info, ~ .x$maintainer)
}

write.xlsx(scraping_packages, "data_scraping_packages_final.xlsx")

##data cleaing

#è¯»å–å·²çˆ¬å–çš„æ•°æ®
descriptions_df <- read.csv(
  "cran_package_meta_descriptions.csv",
  stringsAsFactors = FALSE,
  fileEncoding = "UTF-8"
)

# å®šä¹‰å…³é”®è¯åˆ—è¡¨
cleaning_keywords <- c(
  "clean",
  "preprocess",
  "sanitize",
  "scrub",
  "correct",
  "rectify"
)

# æ£€æŸ¥å¹¶ç§»é™¤ç©ºå…ƒç´ 
cleaning_keywords <- cleaning_keywords[nchar(cleaning_keywords) > 0]

#åˆ›å»ºâ€œæˆ–â€å…³ç³»
pattern <- paste0("\\b(", paste(cleaning_keywords, collapse = "|"), ")\\b")
pattern <- regex(pattern, ignore_case = TRUE)

# ç­›é€‰åŒ…å«å…³é”®è¯çš„åŒ…
cleaning_packages <- descriptions_df %>%
  # è¿‡æ»¤æ‰é”™è¯¯å’Œæœªæ‰¾åˆ°çš„æè¿°
  filter(
    !str_detect(meta_description, "é”™è¯¯:|HTTPé”™è¯¯|Description not found")
  ) %>%
  # æ·»åŠ æ–°åˆ—æ ‡è®°æ˜¯å¦åŒ¹é…å…³é”®è¯
  mutate(
    is_cleaning = str_detect(meta_description, pattern),
    # æå–åŒ¹é…çš„å…³é”®è¯
    matched_keywords = sapply(meta_description, function(desc) {
      matches <- str_extract_all(desc, pattern)[[1]]
      if (length(matches) > 0) {
        paste(unique(tolower(matches)), collapse = ", ") # è½¬æ¢ä¸ºå°å†™å¹¶å»é‡
      } else {
        ""
      }
    })
  ) %>%
  # åªä¿ç•™åŒ¹é…çš„åŒ…
  filter(is_cleaning) %>%
  # é€‰æ‹©éœ€è¦çš„åˆ—
  select(package, meta_description, matched_keywords) %>%
  # æŒ‰åŒ…åæ’åº
  arrange(package)

# æ˜¾ç¤ºå‰10
head(cleaning_packages, 10)

# è¾“å‡ºç»“æœåˆ°Excelæ–‡ä»¶
write.xlsx(cleaning_packages, "data_cleaning_packages.xlsx")

# æ·»åŠ åŒ…é“¾æ¥
cleaning_packages <- cleaning_packages %>%
  mutate(
    cran_link = paste0(
      "https://cran.r-project.org/web/packages/",
      package,
      "/index.html"
    )
  )

# ä¿å­˜ç»“æœ
write.xlsx(cleaning_packages, "data_cleaning_packages_with_links.xlsx")


# åˆ†æ‰¹æ¬¡å¤„ç†åŒ…
batch_size <- 50
batches <- split(
  cleaning_packages$package,
  ceiling(seq_along(cleaning_packages$package) / batch_size)
)

from_date <- Sys.Date() - 90
to_date <- Sys.Date()

# åˆ†æ‰¹è·å–ä¸‹è½½é‡
download_stats_list <- map(batches, function(batch) {
  Sys.sleep(1)
  cran_downloads(
    packages = batch,
    from = from_date,
    to = to_date
  )
})

# åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ
download_stats <- bind_rows(download_stats_list)

download_summary <- download_stats %>%
  group_by(package) %>%
  summarise(total_downloads = sum(count))

cleaning_packages <- cleaning_packages %>%
  left_join(download_summary, by = "package") %>%
  arrange(desc(total_downloads))


write.xlsx(cleaning_packages, "data_cleaning_packages_with_links_rank.xlsx")

# æ·»åŠ ä½œè€…ä¿¡æ¯

get_authors_from_cran <- function(package_name) {
  tryCatch(
    {
      # æ„å»ºDESCRIPTIONæ–‡ä»¶URL
      desc_url <- paste0(
        "https://cran.r-project.org/web/packages/",
        package_name,
        "/DESCRIPTION"
      )

      # å‘é€HTTPè¯·æ±‚
      response <- GET(desc_url, user_agent("Mozilla/5.0"))
      if (http_status(response)$category != "Success") {
        return(list(author = NA, maintainer = NA))
      }

      # è§£æDESCRIPTIONå†…å®¹
      desc_content <- content(response, as = "text")

      # æå–ä½œè€…å’Œç»´æŠ¤è€…ä¿¡æ¯
      author <- if (grepl("Author:", desc_content)) {
        sub(".*Author:([^\n]+).*", "\\1", desc_content) %>% trimws()
      } else {
        NA_character_
      }

      maintainer <- if (grepl("Maintainer:", desc_content)) {
        sub(".*Maintainer:([^\n]+).*", "\\1", desc_content) %>% trimws()
      } else {
        NA_character_
      }

      return(list(author = author, maintainer = maintainer))
    },
    error = function(e) {
      return(list(author = NA, maintainer = NA))
    }
  )
}

# ä¸ºæ¯ä¸ªåŒ…è·å–ä½œè€…ä¿¡æ¯
if (
  !"author" %in% colnames(cleaning_packages) ||
    all(is.na(cleaning_packages$author))
) {
  # åˆ›å»ºè¿›åº¦æ¡
  pb <- progress_bar$new(
    format = "è·å–ä½œè€…ä¿¡æ¯ [:bar] :percent | å·²å¤„ç†: :current / :total | å‰©ä½™: :eta",
    total = nrow(cleaning_packages),
    clear = FALSE
  )

  # è·å–ä½œè€…ä¿¡æ¯
  author_info <- map(cleaning_packages$package, function(pkg) {
    pb$tick()
    Sys.sleep(0.3) # ç¤¼è²Œæ€§å»¶æ—¶
    get_authors_from_cran(pkg)
  })

  # æ·»åŠ ä½œè€…ä¿¡æ¯åˆ°æ•°æ®æ¡†
  cleaning_packages$author <- map_chr(author_info, ~ .x$author)
  cleaning_packages$maintainer <- map_chr(author_info, ~ .x$maintainer)
}

# ä¿å­˜æœ€ç»ˆç»“æœ
write.xlsx(cleaning_packages, "data_cleaning_packages_final.xlsx")

##data transformation

descriptions_df <- read.csv(
  "cran_package_meta_descriptions.csv",
  stringsAsFactors = FALSE,
  fileEncoding = "UTF-8"
)

# å…³é”®è¯åˆ—è¡¨
transformation_keywords <- c(
  "transform",
  "reshape",
  "recode",
  "convert",
  "compute",
  "derive",
  "mutate",
  "modify",
  "reformat",
  "restructure",
  "aggregate"
)

# æ£€æŸ¥å¹¶ç§»é™¤ç©ºå…ƒç´ 
transformation_keywords <- transformation_keywords[
  nchar(transformation_keywords) > 0
]

# åˆ›å»ºæ­£åˆ™è¡¨è¾¾å¼
pattern <- paste0(
  "\\b(",
  paste(transformation_keywords, collapse = "|"),
  ")\\b"
)
pattern <- regex(pattern, ignore_case = TRUE)

# ç­›é€‰åŒ…å«å…³é”®è¯çš„åŒ…
transformation_packages <- descriptions_df %>%
  # è¿‡æ»¤æ‰é”™è¯¯å’Œæœªæ‰¾åˆ°çš„æè¿°
  filter(
    !str_detect(meta_description, "é”™è¯¯:|HTTPé”™è¯¯|Description not found")
  ) %>%
  # æ·»åŠ æ–°åˆ—æ ‡è®°æ˜¯å¦åŒ¹é…å…³é”®è¯
  mutate(
    is_transformation = str_detect(meta_description, pattern),
    # æå–åŒ¹é…çš„å…³é”®è¯
    matched_keywords = sapply(meta_description, function(desc) {
      matches <- str_extract_all(desc, pattern)[[1]]
      if (length(matches) > 0) {
        paste(unique(tolower(matches)), collapse = ", ") # è½¬æ¢ä¸ºå°å†™å¹¶å»é‡
      } else {
        ""
      }
    })
  ) %>%
  # åªä¿ç•™åŒ¹é…çš„åŒ…
  filter(is_transformation) %>%
  # é€‰æ‹©éœ€è¦çš„åˆ—
  select(package, meta_description, matched_keywords) %>%
  # æŒ‰åŒ…åæ’åº
  arrange(package)

# æ˜¾ç¤ºå‰10
head(transformation_packages, 10)

# è¾“å‡ºç»“æœ
write.xlsx(transformation_packages, "data_transformation_packages.xlsx")

# ç»Ÿè®¡ç»“æœ
cat("å‘ç°", nrow(transformation_packages), "ä¸ªä¸æ•°æ®è½¬æ¢ç›¸å…³çš„RåŒ…\n")

# æ·»åŠ åŒ…é“¾æ¥
transformation_packages <- transformation_packages %>%
  mutate(
    cran_link = paste0(
      "https://cran.r-project.org/web/packages/",
      package,
      "/index.html"
    )
  )

# ä¿å­˜ç»“æœ
write.xlsx(
  transformation_packages,
  "data_transformation_packages_with_links.xlsx"
)


# å°†åŒ…åˆ—è¡¨åˆ†æˆè¾ƒå°çš„æ‰¹æ¬¡
batch_size <- 50
batches <- split(
  transformation_packages$package,
  ceiling(seq_along(transformation_packages$package) / batch_size)
)

# è®¾ç½®æ—¶é—´èŒƒå›´
from_date <- Sys.Date() - 90
to_date <- Sys.Date()

# åˆ†æ‰¹è·å–ä¸‹è½½é‡
download_stats_list <- map(batches, function(batch) {
  Sys.sleep(1) # æ·»åŠ å»¶æ—¶é¿å…è¯·æ±‚è¿‡å¿«
  cran_downloads(
    packages = batch,
    from = from_date,
    to = to_date
  )
})

# åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ
download_stats <- bind_rows(download_stats_list)

# è®¡ç®—æ€»ä¸‹è½½é‡
download_summary <- download_stats %>%
  group_by(package) %>%
  summarise(total_downloads = sum(count))

# åˆå¹¶ä¸‹è½½é‡ä¿¡æ¯
transformation_packages <- transformation_packages %>%
  left_join(download_summary, by = "package") %>%
  arrange(desc(total_downloads))


write.xlsx(
  transformation_packages,
  "data_transformation_packages_with_links_rank.xlsx"
)

# æ·»åŠ ä½œè€…ä¿¡æ¯

get_authors_from_cran <- function(package_name) {
  tryCatch(
    {
      # æ„å»ºDESCRIPTIONæ–‡ä»¶URL
      desc_url <- paste0(
        "https://cran.r-project.org/web/packages/",
        package_name,
        "/DESCRIPTION"
      )

      # å‘é€HTTPè¯·æ±‚
      response <- GET(desc_url, user_agent("Mozilla/5.0"))
      if (http_status(response)$category != "Success") {
        return(list(author = NA, maintainer = NA))
      }

      # è§£æDESCRIPTIONå†…å®¹
      desc_content <- content(response, as = "text")

      # æå–ä½œè€…å’Œç»´æŠ¤è€…ä¿¡æ¯
      author <- if (grepl("Author:", desc_content)) {
        sub(".*Author:([^\n]+).*", "\\1", desc_content) %>% trimws()
      } else {
        NA_character_
      }

      maintainer <- if (grepl("Maintainer:", desc_content)) {
        sub(".*Maintainer:([^\n]+).*", "\\1", desc_content) %>% trimws()
      } else {
        NA_character_
      }

      return(list(author = author, maintainer = maintainer))
    },
    error = function(e) {
      return(list(author = NA, maintainer = NA))
    }
  )
}

# ä¸ºæ¯ä¸ªåŒ…è·å–ä½œè€…ä¿¡æ¯
if (
  !"author" %in% colnames(transformation_packages) ||
    all(is.na(transformation_packages$author))
) {
  # åˆ›å»ºè¿›åº¦æ¡
  pb <- progress_bar$new(
    format = "è·å–ä½œè€…ä¿¡æ¯ [:bar] :percent | å·²å¤„ç†: :current / :total | å‰©ä½™: :eta",
    total = nrow(transformation_packages),
    clear = FALSE
  )

  # è·å–ä½œè€…ä¿¡æ¯
  author_info <- map(transformation_packages$package, function(pkg) {
    pb$tick()
    Sys.sleep(0.3)
    get_authors_from_cran(pkg)
  })

  # æ·»åŠ ä½œè€…ä¿¡æ¯åˆ°æ•°æ®æ¡†
  transformation_packages$author <- map_chr(author_info, ~ .x$author)
  transformation_packages$maintainer <- map_chr(author_info, ~ .x$maintainer)
}

# ä¿å­˜ç»“æœ
write.xlsx(transformation_packages, "data_transformation_packages_final.xlsx")

```

::: {.fragment}

```{r}
#| label: myCoding
#| eval: false

library(purrr)
library(pkgsearch)

kw_download <- c("api download", "collect", "gather")
kw_clean <- c("preprocess data", "data clean", "parse", "sanitize", "scrub",  "correct", "rectify", "standardize")
kw_transform <- c("convert data", "reformat", "transform", "aggregate", "rescale", "reshape", "recode", "modify", "restructure")

kw_short <- c(kw_download[1], kw_clean[1], kw_transform[1])

ls_packages <- map(kw_short, \(keyword){
  pkg_search(keyword, format = "long", size = 50) |> 
    select(package, title, maintainer = maintainer_name) 
}) |> 
  set_names(c("download", "clean", "transform")) 
```

:::

:::

## æƒ³æ³•3ï¼šä½¿ç”¨æ–¹å¼

::: {.r-stack}

:::{.r-hstack}

![](https://drhuyue.site:10002/sammo3182/figure/css_xinqingnian1.png){fig-align="center" height=600}

![](https://drhuyue.site:10002/sammo3182/figure/css_xinqingnian2.png){fig-align="center" height=600}

:::

:::{.r-hstack .fragment}

![](https://drhuyue.site:10002/sammo3182/figure/weibo_net-1.png){fig-align="center" height=600}

![](https://drhuyue.site:10002/sammo3182/figure/weibo_net-2.png){fig-align="center" height=600}

:::

:::


::: {.notes}

ã€Šæ–°é’å¹´ã€‹å‰ä¸¤å·çš„æ–‡æœ¬åˆ†æçš„ç»“æœï¼Œå‘Šè¯‰æˆ‘ä»¬ï¼šã€Šæ–°é’å¹´ã€‹å‰æœŸå¹¶éä»…é«˜ä¸¾æ°‘ä¸»å’Œç§‘å­¦çš„å¤§æ——

:::

## ä¸»è§‚ä¸”ä¸è´Ÿè´£åœ°è®¤ä¸º

::::{.overlay-container}

::: {.overlay-image}

![](https://drhuyue.site:10002/sammo3182/figure/css_kanglongyouhui.png){fig-align="center" height=600}

:::

::: {.overlay-text-over .fragment}

- "å°å­©å­æ‰åšé€‰æ‹©"
  - å­¦ä¹ å¤§è¯­è¨€æ¨¡å‹çš„è¿ä½œåŸç†
  - "è¿‘è¯»"è¯»ä¸å‡ºçš„å†…å®¹
- é‡åŠ›è€Œè¡Œ

:::

::::



# æ•¬è¯·æŒ‡æ­£ {background="#43464B"}

:::{style="text-align: right; margin-top: 1em"} 

[`r feather_icons("github")`&nbsp; sammo3182](https://github.com/sammo3182)

[`r feather_icons("mail")`&nbsp; yuehu@tsinghua.edu.cn](mailto:yuehu@tsinghua.edu.cn) 

[`r feather_icons("globe")`&nbsp; https://www.drhuyue.site](https://www.drhuyue.site)

![](https://user-images.githubusercontent.com/6463211/232207708-b0e64eee-7fb3-45a4-9779-ec52397f786c.png){height=250}

:::

## è¯·é—®é¢˜è½¬èº«{.center}

::: {.large .fragment}

1. ç¤¾ä¼šç§‘å­¦å­¦è€…è¦å¼€å§‹ï¼ˆç³»ç»Ÿï¼‰å­¦ä¹ å¤§è¯­è¨€æ¨¡å‹å—ï¼Ÿ
1. ä¼ æ’­å­¦å­¦è€…ä¹‹äºè·¨å­¦ç§‘å­¦è€…çš„*ç†è®ºä¼˜åŠ¿*æ˜¯ä»€ä¹ˆï¼Ÿ
1. æ‚¨ç›¸ä¿¡äººç±»ç¤¾ä¼šå­˜åœ¨*æ™®éè§„å¾‹*å—ï¼Ÿ*

:::

## å‚è€ƒæ–‡çŒ®

:::{.ref}
:::