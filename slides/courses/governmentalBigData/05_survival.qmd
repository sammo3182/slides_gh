---
title: "ç”Ÿå­˜åˆ†æ"
subtitle: "æ”¿åŠ¡å¤§æ•°æ®åº”ç”¨ä¸åˆ†æ (80700673)"
author: "èƒ¡æ‚¦"
institute: "æ¸…åå¤§å­¦" 
knitr: 
    opts_chunk: 
      echo: false
format: 
  revealjs:
    css: https://www.drhuyue.site/slides_gh/css/style_basic.css
    theme: ../../../css/goldenBlack.scss
    slide-number: true
    filters: [appExclusion.lua] # not count appendices into page number
    incremental: true
    preview-links: true # open an iframe for a link
    link-external-newwindow: true
    self-contained: false
    chalkboard: false # allwoing chalk board B, notes canvas C
    # callout-icon: false
    show-slide-number: all # `speaker` only print in pdf, `all` shows all the time
    title-slide-attributes:
      data-background-image: https://gitlab.com/sammo3182/backup/raw/85b3c1ad4b459d7a9f901f124b936428eda5fcaf/logo_THPS.png?inline=true
      data-background-size: 250px   
      data-background-position: top 10% right 5%
    default-image-extension: png
revealjs-plugins:
  - spotlight
lightbox: 
  match: auto
  effect: fade
spotlight:
  size: 50
  presentingCursor: default
  toggleSpotlightOnMouseDown: false
  spotlightOnKeyPressAndHold: 73 # keycode for "i"
editor_options: 
  chunk_output_type: console
---


```{r setup, include = FALSE}
if (!require(pacman))
  install.packages("pacman")
library(pacman)

p_load(dotwhisker, # dependency
       knitr, 
       patchwork,
       drhutools,
       kableExtra,
       tidyverse)

# Functions preload
set.seed(313)

# Visualization
theme_set(
  theme_minimal(base_size = 18)
)

theme_update(
  plot.title = element_text(size = 18), 
  axis.title = element_text(size = 22), 
  axis.text = element_text(size = 18)
)
```

## æ¦‚è¦

![ä»Šå¤©ï¼Œè®©æˆ‘ä»¬æˆä¸ºç”Ÿç‰©å­¦å®¶](https://drhuyue.site:10002/sammo3182/figure/sur_experiment.jpg){ fig-align="center" height=300}

:::{.large .fragment style="text-align:center"}
- ç”Ÿå­˜åˆ†æ[æ¦‚å¿µ]{.red}
- ç”Ÿå­˜åˆ†æ[æ¨¡å‹]{.red}
- ç‰¹æ®Šæƒ…å†µ
:::


# ç”Ÿå­˜åˆ†æ

## ä»€ä¹ˆæ˜¯ç”Ÿå­˜æ•°æ®

::::{.columns}
:::{.column .nonincremental width="50%"}
- ç”Ÿå­˜äºæ•°æ®
    - ä»€ä¹ˆæ—¶å€™å¼€å§‹/ç»“æŸ
    - å»¶ç»­ï¼ˆæ´»ï¼‰äº†å¤šä¹…ï¼Ÿ
    - éœ€è¦å¤šä¹…æ‰èƒ½å‘ç”Ÿï¼Ÿ
    
:::{.fragment}
- ç”Ÿå­˜ä¹‹äºå¤§æ•°æ®
    - [ï¼ˆæŸç§æ„ä¹‰ä¸Šï¼‰æœ€å¸¸è§çš„å¤§æ•°æ®ç±»å‹]{.red}
    - ç¤¾äº¤åª’ä½“åˆ†æ
    - å¸æ³•æ•°æ®åˆ†æ
    - ä½“è‚²æ•°æ®åˆ†æ
    - æ”¿åŠ¡æ•°æ®åˆ†æ    
    â€¦â€¦
:::

:::


:::{.column .fragment .nonincremental width="50%"}
**Terminology**

- Survival analysis
- Event history analysis (discrete)
- Failure analysis
- Duration analysis (continuous)
- Frailty (e.g., engineer)
- Cure models (e.g., medical)

:::{.notes}
Frailty /fr'eÉªlti/ å¼±ç‚¹è„†å¼±
:::
:::

::::


## ç”Ÿå­˜æ•°æ®æœ¬è´¨

:::{style="text-align:center"}
:::{.fragment}
**å½±å“å»ºæ¨¡çš„åŸºç¡€è®¤çŸ¥**

- è§£é‡Šå˜é‡å¯¹äº‹ä»¶çš„å½±å“æ–¹å¼ï¼Ÿ
- äº‹ä»¶æ˜¯å¦è¢«è§†ä¸ºé‡å¤çš„ï¼Ÿ
- å‘ç”Ÿå‘¨æœŸï¼ˆdurationï¼‰æ˜¯å¦æ—¶å®Œå…¨å¯è§çš„ï¼Ÿ
- äº‹ä»¶åˆ†å¸ƒï¼ˆevent rateï¼‰å¦‚ä½•åœ¨æ—¶é—´ç»´åº¦ä¸Šå˜åŠ¨ï¼Ÿ
:::

:::{.fragment .fade-in}
:::{.fragment .grow}
&dArr;

**ä¸‰ç§ç­–ç•¥**

1. *Count*ï¼šå‘ç”Ÿäº†å¤šå°‘æ¬¡
1. *Discrete*ï¼šå¹´ã€æœˆã€å¤©ï¼›0s & 1s.
1. *Continuous*: å…·ä½“æ—¶é•¿
:::
:::
:::

# ç”Ÿå­˜åˆ†ææ¨¡å‹

## Discrete Modeling

> å…³æ³¨äº‹ä»¶å‘ç”Ÿç‚¹ï¼Œè§£é‡Šä¸ä½•å› ç´ æœ‰å…³^[é€šå¸¸è¢«ç§°ä½œâ€œäº‹ä»¶å²â€ï¼ˆevent history)åˆ†æã€‚]

::::{.columns}
:::{.column width="50%" .fragment}
**ä¸»è¦å†³å®š**ï¼š

1. ä½•æ—¶å¼€å§‹è®¡æ—¶
1. å¦‚ä½•åˆ¤å®šäº‹ä»¶å‘ç”Ÿ

**ä¸»è¦æ­¥éª¤**ï¼š

1. å»ºæ„ç»“æœå˜é‡ï¼šé€šå¸¸è¯¥å˜é‡åœ¨äº‹ä»¶å‘ç”Ÿæ—¶è®°ä¸º1ï¼Œä¹‹å‰å‡ä¸º0
1. æµ‹é‡è§£é‡Šå˜é‡ï¼šåœ¨æ¯ä¸ªæ—¶é—´ç‚¹å‡æœ‰è®°å½•

:::

:::{.notes}
è™½ç„¶åˆ†æä¸­å„äº‹ä»¶çœ‹èµ·æ¥æ˜¯åŒæ—¶å¼€å§‹çš„ï¼Œä½†å…¶å®ä¸ç„¶

å½“äº‹ä»¶å‘ç”Ÿåï¼Œè¯¥è§‚æµ‹å•å…ƒå°†ä¸å†å­˜åœ¨äºrisk setä¸­ã€‚
:::

:::{.column width="50%" .fragment}
3. ä¼°è®¡
    - **Risk set**ï¼š åœ¨ç»™å®šæ—¶é—´ç‚¹è§‚æµ‹å•å…ƒè§¦å‘äº‹ä»¶çš„å¯èƒ½æ€§, $R(t)\equiv \{i, y_{it} = 0 | y_{it} = 1\}.$

:::{.fragment}
```{r ehData}
df_eh <- tibble::tribble(
                      ~unit, ~time, ~event, ~ev, ~risk, 
                          1,     1,      0, 4.3,     1,
                          1,     2,      0, 1.2,     1,
                          1,     3,      1, 4.2,     1,
                          1,     4,      NA, 1.6,     0,
                          2,     5,      0, 6.1,     1,
                          2,     6,      0, 3.2,     1,
                          2,     7,      0, 7.2,     1,
                          2,     4,      1, 3.9,     1
                      )

kable(df_eh) |>
  kable_classic(c("striped", "hover"), full_width = F) |>
  kable_styling() |>
  scroll_box(height = "300px")
```
:::

:::
::::

# å‰æ–¹å…¬å¼é¢„è­¦

å…¬å¼å¯¹äºç†è§£ç”Ÿå­˜åˆ†æ[éå¸¸ä¹‹é‡è¦]{.red}!ğŸ¥ğŸ¥ğŸ¥


## æç»˜ç»“æœå˜é‡åˆ†å¸ƒ

:::{.fragment}
Survival rate: the probability that an event will continue to exist ($T$) beyond a certain period of time ($t$).

$$S(t|X) = P(T > t | X).$$
:::

:::{.fragment}
PDF: $f(t|x) = P(T = t | X).$
:::

:::{.fragment}
CDF: $F(t) = P(T\leq t | X) = 1 - S(t).$
:::

:::{.fragment .fade-in}
:::{.fragment .grow}
Hazard: the instantaneous risk at that time of the event happening, given that it hasn't happened yet.

$$P(T = t|T\geq t, X) = \frac{f(t|X)}{S(t|X)} = \frac{P(T \color{red}{=} t | X)}{P(T \color{red}{>} t | X)}.$$
:::
:::

:::{.notes}
Hazard: the probability that the event occurs during a specific time point, given that it hasn't already occurred.
:::

## Hazard, hazard

{{< video https://drhuyue.site:10002/sammo3182/video/sur_tightrope.mp4 title="ä¸€ä¸ªè½»æ¾çš„è§†é¢‘" height=600 loading="eager" allowfullscreen>}}

:::{.notes}
It's like watching a tightrope walker crossing between two skyscrapers. The hazard is the risk of falling at any given moment during the walk, considering the walker hasn't fallen yet.


Example of Hazard in Real Life:

Light Bulbs: Suppose we find that the hazard of a particular brand of light bulbs increases significantly after 1,000 hours of use. This means the risk of these bulbs burning out gets much higher beyond this point.

Patients in a Clinical Trial: If we're studying a new medication, the hazard might represent the risk of a patient having a side effect at any given time during the study, assuming they haven't experienced it yet.
:::

## æ•°æ®æ¼”ç¤º

```{r plot-hazard}
#| fig-align: center

# Generate simulated survival times using an exponential distribution
sample_size <- 10000
scale <- 10
survival_times <- rexp(sample_size, rate = 1 / scale)

# Calculate survival rates for a range of time points
time_points <- seq(0, max(survival_times), length.out = 100)
survival_rates <-
  sapply(time_points, function(t)
    mean(survival_times > t))

# Approximate hazard rates
hazard_rates <- diff(-log(survival_rates)) / diff(time_points)
time_points_hazard <- head(time_points, -1) + diff(time_points) / 2

# Create a unified data frame for plotting
survival_data <-
  data.frame(time = time_points, rate = survival_rates, type = 'Survival Rate')
hazard_data <-
  data.frame(time = time_points_hazard, rate = hazard_rates, type = 'Hazard')

# Combining the data frames
combined_data <- rbind(survival_data, hazard_data)

# Plotting both Survival Rate and Hazard Rate on the same plot
ggplot(combined_data, aes(x = time, y = rate, color = type)) +
  geom_line() +
  scale_y_continuous(name = "Survival Rate", sec.axis = sec_axis( ~ ., name = "Hazard")) +
  ggtitle("Survival Rate and Hazard over Time") +
  xlab("Time") + ylab("Survival Probability") +
  scale_color_gb() + 
  theme(legend.position = "bottom")
```

:::{.notes}
This graph shows the rate at which the event of interest is expected to occur at different times, given that it hasn't occurred yet.
:::

## äº‹ä»¶å²åˆ†æå·¥å…· {auto-animate=true}

:::{.large .nonincremental style="text-align:center; margin-top: 2em" auto-animate=true}
- logit/probit
- c-log-log
- scobit
- expit
:::

:::{.notes}
c-log-log: complementary log-log, $\eta(x) = \log(-\log(1-\pi_x))=\mathbf{x}\beta$

scobit: skewed logit

expit: exponential logit
:::

## Logit/Probitæ¨¡å‹ {auto-animate=true}

::::{.columns}
:::{.column width="30%" .nonincremental auto-animate=true}
- [logit/probit]{.red}
- c-log-log
- scobit
- expit
:::

:::{.column width="70%" .fragment}
ä»¤ $Y^*$ ä¸ºå¯¼è‡´å¯è§äº‹ä»¶( $Y_{it}$ )å‘ç”Ÿçš„ä¸å¯è§å˜é‡ï¼š

$$Y_{it} =
  \begin{cases} 
   1 & \text{if } Y^*\geq 0, \\
   0 & \text{if } Y^*< 0.
  \end{cases}$$
  
:::{.fragment}
é‚£ä¹ˆ

\begin{align}
P(Y_{it} = 1|X) =& P(Y^* \geq 0|X)\\
              =& P(X\beta + \epsilon\geq 0|X)\\
              =& P(\epsilon\geq 0 - X\beta|X)\\
              =& 1 - P(\epsilon\leq - X\beta|X)\\
              =& 1 - F(-X\beta|X)
\end{align}
:::
:::
::::


## Logitæ¨¡å‹

ä»¤ $\epsilon\sim logistic$,^[
å¯¹äºprobitï¼Œåˆ™ä»¤ $\epsilon\sim i.i.d. N(0, 1)$, åˆ™ $P(Y_it = 1|X) = 1 - \Phi(-X\beta) = \Phi(X\beta).$] åˆ™ $$P(Y_it = 1|X) = 1 - \Lambda(-X\beta) = \Lambda(X\beta).$$

:::{.fragment}
ä»£å…¥logisticåˆ†å¸ƒå¯å¾—ï¼Œ

\begin{align}
P(Y_{it} = 1|X) =& 1 - \frac{e^{-X\beta}}{1 + e^{-X\beta}}\\
              =& \frac{e^{X\beta}}{1 + e^{X\beta}}\\
P(Y_{it} = 0|X) =& \frac{1}{1 + e^{X\beta}}
\end{align}
:::

:::{.notes}
$\beta_{probit} = \frac{\sqrt 3}{\pi}\beta_{logit}.$

æ­¤å¤„ç”¨probabilityæ¥å»ºæ„likelihood, å› ä¸ºlikelihoodå­˜åœ¨scale issue, é€šå¸¸ä¸å¯çŸ¥ã€‚æ­¤æ³•è¢«Garyç§°ä¸ºUnified Maximum Likelihood
:::


## åº”ç”¨ä¸¾ä¾‹

ç ”ç©¶ç¾å›½å°ç¬¬å®‰éƒ¨è½ä¸å·åè°ƒæ³•æ¡ˆï¼ˆIndian Gaming Compactï¼‰æ¨è¡Œæƒ…å†µ

```{r eg_discrete_prepare, include=FALSE, eval=FALSE}
df_eh <- read_dta("D:/MEGAsync/00_Methods/Courses/Method Courses/306 Time and Space/Computer lab/306comp10discrete-indvars.dta")
df_ehdv <- read.table("D:/MEGAsync/00_Methods/Courses/Method Courses/306 Time and Space/Computer lab/306comp10discrete-adoptions.txt", col.names = c("state", "adopt_year"), stringsAsFactors = FALSE)
df_iga <- left_join(df_eh, df_ehdv)

saveRDS(df_iga, file = "data/iga.RDS")
```

:::: {.columns}

::: {.column .nonincremental width="40%"}
è§£é‡Šå˜é‡ï¼š

- Religion (`religion`), the number of federally recognized tribes (`fedtrib`)
- Total population (`totpop`)
- Real income per capita (`rpcpinc`)
- Ideology score (`ideology`)
- Federal government recognized tribes (`fedtribe`)
:::

::: {.column .fragment width="60%"}
```{r eg_discrete1}
# Reading the raw data
df_iga <- readRDS(url("https://drhuyue.site:10002/sammo3182/data/iga.RDS"))
head(df_iga) %>% 
  kable(caption = "åŸå§‹æ•°æ®å½¢æ€") |>
  kableExtra::kable_classic(c("striped", "hover"), full_width = F)
```
:::

::::

## å»ºç«‹Risk set

$R(t)\equiv \{i, y_{it} = 0 | y_{it} = 1\}.$

:::{.notes}
åœ¨ç»™å®šæ—¶é—´ç‚¹è§‚æµ‹å•å…ƒè§¦å‘äº‹ä»¶çš„å¯èƒ½æ€§, å¯¹äºä¸€ä¸ªå‘¨ï¼Œæ²¡æ¨è¡Œæ˜¯1ï¼Œæ¨è¡Œäº†åˆ™è¢«å‡å»
:::

```{r eg_discrete2}
# Creating the event history record
df_iga$adopt_ig <- NA
df_iga$adopt_ig[df_iga$year == df_iga$adopt_year] <- 1
df_iga$adopt_ig[df_iga$year < df_iga$adopt_year |
                  is.na(df_iga$adopt_year)] <- 0

# Creating the risk set
df_iga$risk_ig <- NA
df_iga$risk_ig[df_iga$year <= df_iga$adopt_year |
                 is.na(df_iga$adopt_year)] <- 1

df_igaSum <- group_by(df_iga, year) %>%
  summarise(
    sum_adopt = sum(adopt_ig, na.rm = TRUE),
    sum_risk = sum(risk_ig, na.rm = TRUE)
  ) %>%
  mutate(hazard = sum_adopt / sum_risk, 
         survival = sum_risk / 50)

kable(df_igaSum, digits = 2, caption = "å¯åˆ†ææ•°æ®å½¢æ€") |>
  kable_classic(c("striped", "hover"), full_width = F) |>
  kable_styling() |>
  scroll_box(height = "550px")
```

## Kaplan-Meier Curve

A.k.a, *product limit estimator*, often seen in medical research

```{r eg_discrete3}
#| fig-align: center

ggplot(df_igaSum, aes(x = year, y = survival)) +
  geom_line() +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  theme(
    plot.title = element_text(size = 18), axis.title = element_text(size = 22), axis.text = element_text(size = 18)
  ) + ylab("Rate")
```

:::{.notes}
Kaplan-Meier curve shows what the probability of an event (for example, survival) is at a certain time interval. 
:::

## Estimation

```{r eg_discrete4}
#| echo: true
#| fig-align: center
#| code-line-numbers: "|6"
#| fig-height: 4
#| output-location: fragment

library(survival)

m_logit <-
  survreg(
    Surv(time = year, event = adopt_ig) ~ religion + totpop + rpcpinc + fedtribe, data = df_iga, 
    dist = "logistic")

dwplot(m_logit, show_stats = TRUE, vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))
```

# Duration Analysis

## Duration: An Alternative

:::{style="text-align:center"}
**EH vs. Duration**

Event historyï¼šäº‹ä»¶å‘ç”Ÿçš„æ—¶é—´ç‚¹

Durationï¼šæ€»ä½“æ—¶é—´æ®µ
:::


```{r eg_dur_prepare, include=FALSE, eval=FALSE}
df_dur <- read_dta("D:/MEGAsync/00_Methods/Courses/Method Courses/306 Time and Space/Homeworks/306hwk07-coalcold.dta")

names(df_dur) <- tolower(names(df_dur))

df_dur <- select(df_dur, durat, invest, fract, polar, numst2, format, eltime2, caretk2) %>% 
  mutate_at(c("invest", "numst2", "eltime2", "caretk2"), function(var) var = var - 1)

saveRDS(df_dur, file = "data/coalcold.RDS")
```

:::{.fragment}
```{r durData}
df_dur <- tibble::tribble(
           ~duration, ~opposition, ~polarization, ~Beilgium, ~Canada,
                   3,    -0.86792,            11,         1,       0,
                   7,    -0.86792,            11,         1,       0,
                  20,    -0.14103,            11,         1,       0,
                   6,    -0.14103,            11,         0,       1,
                  17,    -0.58065,             6,         0,       1,
                   7,    -0.79592,             3,         0,       1
           )


kable(df_dur, caption = "Duration Data") |>
  kableExtra::kable_classic(c("striped", "hover"), full_width = F)
```
:::

## Modeling the duration

- é€‰æ‹©
    - Parametric models
    - Semi-parametric models (e.g., cox)
- é€‰æ‹©æœ¬è´¨ï¼šé€‰å®šbaseline hazard

:::{.large style="text-align:center; margin-top: 1em"}
*æœ€å¸¸è§çš„å››ç§å‚æ•°æ¨¡å‹*

1. Exponential
1. Weibull
1. Log-normal
1. Gamma
:::

## Exponential model

::::{.columns}
:::{.column width="50%"}
![ç‰¹ç‚¹ï¼šMemoryless, hazard constant](https://drhuyue.site:10002/sammo3182/figure/sur_colonyGrowth.gif){fig-align="center" height=500}

:::

:::{.column width="50%" .fragment}
$$
\begin{align}
S(u) =& e^{-u} = f(u),\\
F(u) =& 1 - e^{-u},\\
h(u) =& 1
\end{align}
$$

:::{.fragment}
```{r expFun}
#| fig-align: center
#| fig-height: 7

ggplot(data.frame(x = c(0, 5)), aes(x = x)) +
  stat_function(
    fun = function(x)
      dexp(x, rate = 0.5),
    aes(colour = "0.5")
  ) +
  stat_function(
    fun = function(x)
      dexp(x, rate = 1),
    aes(colour = "1")
  ) +
  stat_function(
    fun = function(x)
      dexp(x, rate = 1.5),
    aes(colour = "1.5")
  ) +
  ylab("Probability Density") +
  xlab("X") +
  labs(color = "u") + 
  scale_color_gb(palette = "tricol")
```
:::

:::{.notes}
exponential: $e^n$
:::
:::
::::



## Weibull

::::{.columns}
:::{.column width="40%" .fragment}
ç‰¹ç‚¹ï¼šç”¨pè°ƒèŠ‚baselineæ–¹å‘

p < 1, å•å‡   
p = 1, = exponential    
p > 1, å•å¢
:::

:::{.column width="60%" .fragment}
$$
\begin{align}
S(u)_{exp} =& e^{-u}\rightarrow S(u)_{weibull} = e^{-u^\color{red}{p}},\\
F(u) =& 1 - e^{-u^p}; f(u) = pu^{p - 1}e^{-u^p},\\
h(u) =& pu^{p - 1}
\end{align}
$$
:::
::::

:::{.fragment}
```{r wbFun}
#| fig-align: center
#| fig-height: 4

ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
  stat_function(
    fun = function(x)
      dweibull(x, shape = 0.5),
    aes(colour = "0.5")
  ) +
  stat_function(
    fun = function(x)
      dweibull(x, shape = 1),
    aes(colour = "1")
  ) +
  stat_function(
    fun = function(x)
      dweibull(x, shape = 10),
    aes(colour = "10")
  ) +
  ylab("Probability Density") +
  xlab("X") +
  labs(color = "p") + 
  scale_color_gb(palette = "tricol")
```
:::

## Log-normal

ç‰¹ç‚¹ï¼š å…è®¸éå•è°ƒhazard, $ln(u_i)\sim N(\mu, \sigma^2).$

```{r lnFun}
#| fig-align: center
#| fig-height: 6

ggplot(data.frame(x = c(0, 2.5)), aes(x = x)) +
  stat_function(
    fun = function(x)
      dlnorm(x, meanlog = 0, sdlog = 1),
    aes(colour = "0, 1")
  ) +
  stat_function(
    fun = function(x)
      dlnorm(x, meanlog = 0, sdlog = 0.5),
    aes(colour = "0, 0.5")
  ) +
  stat_function(
    fun = function(x)
      dlnorm(x, meanlog = 0.5, sdlog = 0.5),
    aes(colour = "0.5., 0.5")
  ) +
  ylab("Probability Density") +
  xlab("X") +
  labs(color = expression(mu ~ "," ~ sigma)) + 
  scale_color_gb(palette = "tricol")
```


## Gamma(&Gamma;) {auto-animate=true}

::::{.columns}
:::{.column width="40%" .fragment}
p: the scale parameter    
&kappa;: the shape parameter
:::

:::{.column width="60%" .fragment}
$$f(u) = pu^{p - 1}e^{-u^p}\rightarrow f(u) = \frac{pu^{p\color{red}{\kappa} - 1}e^{-u^p}}{\color{red}{\Gamma(\kappa)}}.$$
:::
::::

:::{.fragment}
```{r gamma}
#| fig-align: center
#| fig-height: 5

ggplot(data.frame(x = c(0, 20)), aes(x = x)) +
  stat_function(
    fun = function(x)
      dgamma(x, shape = 1, scale = 2),
    aes(color = "1, 2")
  ) +
  stat_function(
    fun = function(x)
      dgamma(x, shape = 9, scale = 2),
    aes(color = "9, 2")
  ) +
  stat_function(
    fun = function(x)
      dgamma(x, shape = 9, scale = .5),
    aes(color = "9, .5")
  ) +
  ylab("Probability Density") +
  xlab("X") +
  labs(color = expression("p, " ~ kappa)) + 
  scale_color_gb(palette = "tricol")
```
:::

## Bonus: Generalized &Gamma; Distribution {auto-animate=true}

$$f(u) = \frac{\color{orange}{p}u^{\color{orange}{p}\color{blue}{\kappa} - 1}e^{-u^\color{orange}{p}}}{\color{red}{\beta}^{\color{orange}{p}\color{blue}{\kappa}}\Gamma(\color{blue}{\kappa})}$$

:::{.fragment style="text-align:center; margin-top: 2em"}
[&beta;]{.red} = 1 &rArr; Gamma;

[&kappa;]{.blue} = 0 &rArr; log-normal;

[&kappa;]{.blue} = 1 &rArr; Weibull;

[&kappa;]{.blue} = [p]{.orange} = 1 &rArr; Exponential.
:::

:::{.notes}
$\beta$: èƒ½å­˜æ´»çš„æ—¶é—´ã€‚

Exponentialï¼ŒWeibullï¼ŒLog-normal, Gamma éƒ½æ˜¯Generalized Gammaçš„ç‰¹æ®Šå˜å½¢

Ref: http://reliawiki.org/index.php/The_Generalized_Gamma_Distribution
:::


## è§£é‡ŠHarzard

DGP: $Y_i = e^{X_i\beta}u_i\Rightarrow u_i = \frac{Y_i}{e^{X_i\beta}} = Y_ie^{-X_i\beta}$.

:::{.fragment style="margin-top: 1em"}
ä»¤$\lambda\equiv e^{-X_i\beta}$, é‚£ä¹ˆï¼Œå¯¹äºexponential

$$
\begin{align}
u_i =& Y_i\lambda_i \\
F(Y_i|X) =& 1 - e^{-Y_i\lambda_i}\\
f(Y_i|X) =& \lambda_ie^{-Y_i\lambda_i}\\
h(Y_i|X) =& \lambda_i = e^{-Y_i\lambda_i}
\end{align}
$$
:::

:::{.fragment}
åŒç†ï¼Œå¯¹äºWeibull, $h(Y_i|X) = p\lambda^pY^{p - 1}.$
:::

## Xæ”¹å˜çš„æ˜¯ä»€ä¹ˆ

**Expected value**

+ Exponential: $E(Y_i|X_i) = \lambda_i^{-1} = exp(X_i\beta)$
+ Weibull: $E(Y_i|X_i) = \Gamma(p)exp(X_i\beta)$

:::{.fragment}
**Hazard ratio**

$$
\begin{align}
\frac{h(Y_i|X + 1)}{h(Y_i|X)} =& \frac{pexp[-(X_i + 1)\beta]^py_i^{p - 1}}{pexp(-X_i\beta)^py_i^{p - 1}}\\
=& exp(-\beta)^p = e^{\color{red}{-\beta p}}
\end{align}
$$

:::{style="text-align:center; margin-top: 1em"}
-&beta;p: proportional hazard metric;

&beta;: accumulative failure time metric.
:::

:::

## Semi-parametric model

Cox modelï¼šä¸å¯¹Baseline hazardå½¢çŠ¶åšå‡è®¾


ä»¤$\lambda\equiv e^{-X_i\beta}$ï¼Œ 

$$
\begin{align}
h(t|x) =& \overbrace{h_0(t)}^{Non-parametric}\lambda_i^p,\\
P(1fails@t_1|someone\ f@t_1) =& \frac{h_0(t_1)\lambda_i^p}{\sum^n_{i = 1}h_0(t_1)\lambda_i^p},\\
P(2fails@t_2|someone\ f@t_2) =& \frac{h_0(t_2)\lambda_i^p}{\sum^n_{i = 2}h_0(t_1)\lambda_i^p}
\end{align}
$$

:::{.notes}
ç”±äºä¸æ˜¯å®Œå…¨parametricï¼Œæ‰€ä»¥å¤šåªè¿›è¡Œå±€éƒ¨æ£€éªŒï¼Œå› æ­¤ä¸å¸¸åœ¨æ—©æœŸæ”¿æ²»ç§‘å­¦ç ”ç©¶ä¸­å‡ºç°ã€‚
:::

## åº”ç”¨å®ä¾‹

:::{.r-stack}

```{r eg_dur1, fig.width=10}
df_dur <- readRDS(url("https://drhuyue.site:10002/sammo3182/data/coalcold.RDS"))

library(survminer)

survfit(Surv(time = durat) ~ 1, data = df_dur) %>% 
  ggsurvplot(title = "(Data based) Kaplan-Meier Curve")
```

:::{.fragment}
```{r eg_dur2}
model_dur <-
  formula(Surv(time = durat) ~ invest + fract + polar + numst2 + format + eltime2 + caretk2)

m_exp <- survreg(model_dur, data = df_dur, dist = "exponential")
m_wb <- survreg(model_dur, data = df_dur, dist = "weibull")
m_ln <- survreg(model_dur, data = df_dur, dist = "lognormal")
m_cox <- coxph(model_dur, data = df_dur)

result_dur <- list(m_exp, m_wb, m_ln)

plot_dur <-
  map2_df(result_dur, c("Exponential", "Weibull", "Log-normal"), function(result, modelNM) {
    result <- summary(result)$table %>% 
      as_tibble(rownames = "term")
    names(result) <-
      c("term", "estimate", "std.error", "statistic", "p.value")
    result$model <- modelNM
    return(result)
  }) %>% filter(!str_detect(term, "\\(")) # removed noninformal coefs

result_cox <-
  summary(m_cox)$coefficients %>% 
  as_tibble(rownames = "term") %>% 
  select(-`exp(coef)`) %>% 
  mutate(coef = -coef)

names(result_cox) <-
  c("term", "estimate", "std.error", "statistic", "p.value")

result_cox$model <- "Cox"

plot_dur <- bind_rows(plot_dur, result_cox)

dwplot(plot_dur)  + 
  geom_vline(xintercept = 0, 
             colour = "grey60", 
             linetype = 2) +
  scale_color_gb() 
```

:::{.notes}
Random tree for duration: https://rviews.rstudio.com/2017/09/25/survival-analysis-with-r/
:::

:::

:::


## Want to be an *Expert* Expert

:::: {.columns}

::: {.column width="50%"}

![](https://drhuyue.site:10002/sammo3182/figure/sur_survivalBook.jpg){fig-align="center" height=600}
:::

::: {.column .fragment width="50%"}
*Operation*

[Survival Analysis with R](https://rviews.rstudio.com/2017/09/25/survival-analysis-with-r/)

[Survival Task View](https://cran.r-project.org/web/views/Survival.html)

![](https://drhuyue.site:10002/sammo3182/figure/sur_survminer.png){fig-align="center" height=450}
:::

::::


# ç‰¹æ®Šæƒ…å†µ

A.k.a., çœŸå®ä¸–ç•ŒğŸ˜

## ç”Ÿå­˜åˆ†æä¼šä½œä»€ä¹ˆå¦–

- Duration dependency (e.g., life-stage effects)
- Censored data (yeah, you can't see it)
- Time Varying Covariates ï¼ˆCox does not allow TVC)
- Repeated Failure (å±¡æˆ˜å±¡è´¥/å±¡è´¥å±¡æˆ˜)
- Competing Risk (What if the events are not indepdent)
- Ties (Tie in competition)
- Split Population (ä¸è´¥ vs. ä¸è´¥yet)
- Non-proportional Hazard (æ¯ä¸ªè§‚æµ‹ç‚¹çš„basedline hazard functionéƒ½ä¸€æ ·å—ï¼Ÿ)
- Rare events (e.g., wars, human traffic, being an genius)       
  ......


## Duration Dependency

> Baseline hazardéšæ—¶é—´æ”¹å˜


è§£å†³æ–¹æ³•:

:::: {.columns}

::: {.column width="40%"}
* Fixed effect
* Smooth function: $t, t^2, t^3$("nearly identical substantively [with spline]").^[Carter, David B., and Curtis S. Signorino. 2010. "Back to the Future: Modeling Time Dependence in Binary Data." *Political Analysis* 18(3): 271â€“92.]
:::

::: {.column width="60%"}
* ![Spline](https://drhuyue.site:10002/sammo3182/figure/sur_spline.png){fig-align="center" height=300}
:::

::::


## Rare Event

å¯¹äºå°æ¦‚ç‡äº‹ä»¶ï¼ˆ< 5%ï¼‰&rarr; ä½¿ç”¨logitä¼š[é«˜ä¼°]{.red}Pr(Y = 1)ã€‚


è§£å†³æ–¹æ³•ï¼š^[King, Gary, and Langche Zeng. 2001. â€œLogistic Regression in Rare Events Data.â€ *Political analysis* 9(2): 137â€“63.]

> å‡å®šæ²¡æœ‰å…¶ä»–æ›´å¥½sample

1. Prior correction: åŠ å…¥åŸºäºå…¶ä»–ç ”ç©¶æˆ–ç ”ç©¶è€…è®¤çŸ¥çš„å…³äºæ€»ä½“åˆ†å¸ƒçš„è¶‹åŠ¿ä¼°è®¡ã€‚
    + æ³¨æ„ï¼šå¦‚æœæ¨¡å‹æœ‰è¯¯çš„è¯ï¼Œç»“æœä¹Ÿä¸ä¼šç¨³å¥ã€‚
1. Post-estimation weighting: $$P(Y_i = 1) \approx \tilde{\pi_i} + C_i,$$ $C_i$è¾“å…¥æŸäº›æ€»ä½“åˆ†å¸ƒä¿¡æ¯ã€‚


## Last but not the least

ä¸‰ç§å°†æ—¶é—´çº³å…¥äº‹ä»¶çš„æ–¹å¼ (Count, binary, duration)ï¼Œé€‰å“ªä¸ªï¼Ÿ

:::{.fragment}

|          | Pros                                              | Cons                                                                               |
|----------|---------------------------------------------------|------------------------------------------------------------------------------------|
| Count    | Aggregative, prevent measurement error            | Lose the ability to record any identified variations over time and the time series |
| Duration | Record the time and changing moment and sequences | Lose the precision of when within each time unit an event occurs                   |
| Binary   | Most disaggregate                                 | Lose when the change happens in a time line                                        |

:::

- ä¸‰ç§æ–¹æ³•éƒ½æ˜¯å¯¹åŒä¸€ç°è±¡çš„åæ˜ ^[Carstensen, Bendix. 2012. â€œWho Needs the Cox Model Anyway.â€ *Stat Med* 31: 1074â€“88, demonstrating the equivalence of the Cox model to a particular Poisson regression.
]
- ä¸‰ç§modelså®é™…è§£é‡Šå¯èƒ½ä¸ä¸€æ ·ï¼Œå› ä¸ºéƒ½æ˜¯å¯¹ç°å®çš„[de-]{.red}information

:::{.notes}
https://rviews.rstudio.com/2022/09/06/deep-survival/
:::

## Take-Home Points

:::: {.columns}

::: {.column .nonincremental width="50%"}
  - ç”Ÿå­˜åˆ†ææ¦‚å¿µ
    - äº‹ä»¶å‘ç”Ÿ/ç»“æŸçš„â€œç‚¹â€ä¸â€œçº¿â€
    - å¤§æ•°æ®æœ€åŸºç¡€æ•°æ®
  - ç”Ÿå­˜åˆ†ææ¨¡å‹
      - [Count]{.grayLight}
      - Discrete: logistic
      - Duration: exponetional, weibull, log-normal, cox
  - æ¨¡å‹é€‰æ‹©ï¼šCount, binary, duration---de-information
:::

::: {.column .nonincremental width="50%"}
- ç‰¹æ®Šæƒ…å†µ
  - Duration dependency
  - [Censored data]{.grayLight}
  - [Time Varying Covariates]{.grayLight}
  - [Repeated Failure]{.grayLight}
  - [Competing Risk]{.grayLight}
  - [Ties]{.grayLight}
  - [Split Population]{.grayLight}
  - [Non-proportional Hazard]{.grayLight}
  - Rare events
:::

::::


# é™„å½• {.appendix visibility="uncounted"}

## (Right) Censor

Censored pointä¸ºc, åˆ™ï¼š

$$L = \prod^{n}_{i=1}f(y_i|x_i)^{1 - c}S(y^c|X_i)^c,$$ where

$$c =
  \begin{cases} 
   1 & \text{if } y_i\geq y_c, \\
   0 & \text{if } y_i< y_c.
  \end{cases}$$

:::{.fragment}
å½“censoredéƒ¨åˆ†æ‰©å¤§ï¼Œæ¨¡å‹çš„efficiencyä¼šé™ä½ã€‚
:::

:::{.fragment}
å¦‚å°†selection effectä¹Ÿè€ƒè™‘è¿›å»çš„æ—¶å€™ï¼Œéœ€è¦modeling selection process^[Boehmke, Frederick J., Daniel S. Morey, and Megan Shannon. 2006. â€œSelection Bias and Continuous-Time Duration Models: Consequences and a Proposed Solution.â€ *American Journal of Political Science* 50(1): 192â€“207.]
:::

## Time Varying Covariates (TVC)

Assumption (Cox): Covariates do not vary over time.

:::{.fragment}
Discrete model: Combine in the logit
:::

:::{.fragment}
Parametric: Conditional likelihood function (CTD: Continuous Time Duration)

\begin{align}
P(y_i>1|X_1(1)) =& \frac{P(y_i>2, y_i>1|X_1(2))}{P(y_i>1|X_1(2))}\\
=& S(1|X_1(1))p(y_i>2|y_i>1, X_1(2))\\
=& \frac{S(2|X_1(2))}{S(1|X_1(2))}
\end{align}
:::

:::{.fragment}
Cox: put the value of that time moment, $X_i(t)$,  at failure time t in continuing the partial likelihood.
:::

:::{.notes}
Partial likelihood:

\begin{align}
L_p = \prod^K_{i = 1}[\frac{e^{X_i}\beta}{\sum_{j\in R(t_i)}e^{X_i\beta}}]^{\sigma_i}
\end{align}

Assumption: intervals between successive duration time does not help to explain the relationship between covariates and hazard.
:::


## Repeated Failure

*Type*ï¼š

1. Total: æ¯æ¬¡éƒ½é‡æ–°å¼€å§‹
1. Gap: ä»ç‰¹å®šæ—¶é—´ç‚¹å¼€å§‹è®¡ç®—
1. Counting: æ¯ä¸ªè§‚æµ‹ç‚¹éƒ½åœ¨åŒä¸€æ—¶é—´èŒƒç•´ï¼Œä½†å…è®¸æ™šè¿›å’Œcensor

:::{.fragment}
&rArr; *Risk set*:
:::

* Unrestricted: åœ¨æ‰€æœ‰failureäº‹ä»¶ä¸­ï¼Œæ‰€æœ‰è§‚æµ‹ç‚¹æ— è®ºä¹‹å‰ç»å†è¿‡å¤šå°‘æ¬¡failureéƒ½ä¼šç»§ç»­åœ¨risk setä¸­
* Semi-restricted: åœ¨ç¬¬Kæ¬¡failureäº‹ä»¶ä¸­ï¼Œrisk setä¸­åªåŒ…å«ç»å†è¿‡k-1æ¬¡æˆ–å°‘äºk-1æ¬¡äº‹ä»¶çš„è§‚æµ‹ç‚¹
* Restricted: åœ¨ç¬¬Kæ¬¡failureäº‹ä»¶ä¸­ï¼Œrisk setä¸­åªåŒ…å«ç»å†è¿‡k-1æ¬¡äº‹ä»¶çš„è§‚æµ‹ç‚¹

## ä¼°è®¡æ–¹æ³•

![](https://drhuyue.site:10002/sammo3182/figure/sur_repeatedFailure.jpg){fig-align="center" height=400}


## Competing Risk

*ä¸¤ç§æ–¹æ³•*ï¼š

- å‡å®šç«äº‰äº‹ä»¶ç‹¬ç«‹ï¼Œè¿›è€Œåˆ†åˆ«å»ºæ¨¡â€”â€”å°†ç«äº‰æ€§è§†ä¸ºcensored
- å‡å®šç«äº‰äº‹ä»¶éç‹¬ç«‹ï¼Œå¼•å…¥shared frailties:

:::{.fragment}
\begin{align}
h(y_1) =& h_0(y)exp(X\beta + v_1)\\
h(y_2) =& h_0(y)exp(X\beta + v_2)
\end{align}
:::

:::{.fragment}
ç”¨$(v_1, v_2)$ jointed distributed æ¥çº³å…¥éç‹¬ç«‹æ€§ã€‚
:::

## Tie

* Evenly divide &lambda; in the nominators of two tied events.
* The most popular methods: Efron, Preslow.

## Split Population (Cure Models)

å¯èƒ½æœ‰ä¸¤ç§æ„ä¹‰:

1. Never fail
1. Right censored

è§£å†³æ–¹æ³•ï¼š

å¯¹Cureè¿›è¡Œå»ºæ¨¡ï¼Œ$Z_i$: 1 (cured), 0 (not cured), å…¶pdfä¸º $P(Z_i = 1)$ , é‚£ä¹ˆå¯¹äº0æ¥è¯´å…¶survial modelä¸º $S(y|x)P(Z = 0)$.

## Non-proportional Hazard

æ¯ä¸ªè§‚æµ‹ç‚¹çš„basedline hazard functionéƒ½ä¸€æ ·å—ï¼Ÿ

:::: {.columns}

::: {.column .nonincremental width="50%"}
æ£€éªŒ:

1. Piecewise regression
1. Model with interaction
1. Schoenfeld residual plot
:::

::: {.column width="50%"}
![](https://drhuyue.site:10002/sammo3182/figure/sur_residualPlot.png){fig-align="center" height=300}
:::

::::

:::{.fragment}
è§£æ³•

$$y_i = X\beta_1 + Xln(t)\beta_2 + ln(t)\beta_3.$$

:::

