<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>潜在变量分析（基础）</title>
    <meta charset="utf-8" />
    <meta name="author" content="胡悦" />
    <script src="03_latentVariableI_files/header-attrs-2.6/header-attrs.js"></script>
    <link href="03_latentVariableI_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="03_latentVariableI_files/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
    <link href="03_latentVariableI_files/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
    <link href="03_latentVariableI_files/tile-view-0.2.4/tile-view.css" rel="stylesheet" />
    <script src="03_latentVariableI_files/tile-view-0.2.4/tile-view.js"></script>
    <link href="03_latentVariableI_files/tachyons-4.12.0/tachyons.min.css" rel="stylesheet" />
    <link href="03_latentVariableI_files/panelset-0.2.4/panelset.css" rel="stylesheet" />
    <script src="03_latentVariableI_files/panelset-0.2.4/panelset.js"></script>
    <script src="03_latentVariableI_files/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="03_latentVariableI_files/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="03_latentVariableI_files/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="03_latentVariableI_files/xaringanExtra-broadcast-0.2.4/broadcast.css" rel="stylesheet" />
    <script src="03_latentVariableI_files/xaringanExtra-broadcast-0.2.4/broadcast.js"></script>
    <script src="03_latentVariableI_files/htmlwidgets-1.5.3/htmlwidgets.js"></script>
    <script src="03_latentVariableI_files/viz-1.8.2/viz.js"></script>
    <link href="03_latentVariableI_files/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
    <script src="03_latentVariableI_files/grViz-binding-1.0.6.1/grViz.js"></script>
    <link rel="stylesheet" href="zh-CN_custom.css" type="text/css" />
    <link rel="stylesheet" href="style_ui.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# 潜在变量分析（基础）
## Learning Latent Variable Analysis with Dr. Hu (Basic)
### 胡悦
### 清华大学政治学系

---





## 内容概要

* 潜在变量分析概述
* 什么是EFA
    + EFA诊断
    + EFA vs. PCA
* 什么是CFA
    + CFA诊断
* SEM 入门

---

## 操作语言

* R
    + [`psych`](https://personality-project.org/r/psych/vignettes/intro.pdf)
    + [`laavan`](https://lavaan.ugent.be/)

---

class: inverse, bottom

# 潜在变量分析：一种方法

---

## 潜在变量

.left-column[
&lt;img src="images/lv_LoveLife.jpg" height = 400 /&gt;
]

???

Anna Kendrick's 2020 show, showing how difficult to find "the one." This "being loved" is a latent variable.

--

.right-column[

1. 不可见(Unobservable)
1. 多维度(Multidimensional)
1. 有效果(Consequential)

]

???

兜里有多少钱，不可见，但维度单一，不宜用潜变量分析，更好的办法是翻兜

The latent variable per se can't be directly measured. But its consequences in opinions and behaviors can be observed.

---

## 为什么需要了解潜在变量？

公共舆论、政治文化、政治心理……几乎所有社会科学学科：

* 抽象
* 复杂
* 综合

--

".red[Cornerstone] of successful scientific inquiry."  
---Delli Carpini and Keeter 1993

???

Delli Carpini, M. X., and S. Keeter. 1993. “Measuring Political Knowledge: Putting First Things First.” American Journal of Political Science 37 (4): 1179–1206.

---

## 怎么找？

例：测量个体的“社会资本”（social capital）

指标问题X（1~10）：

1. 您是否信任身边人？
1. 您在政府机关有没有亲戚
1. 您的朋友是否和您的想法经常一致？

`$$\tilde{X} = (X_1 + X_2 + X_3)/3.$$`

累加型综合法(additive scales)

---

Getting the mean right (?)

--

1. 平等权重(equal weight)
1. 数据敏感(extreme value sensitivity)
1. 忽略极化(polarity ignoring)

---

## "易求无价宝，难得有心郎！"

### 因素分析模型(Factorial Models)

1. 探索性因子分析(EFA)
1. 验证性因子分析(CFA)
1. 结构方程模型(SEM)

### .gray[类型分析模型(Typological Models)]


1. .grayLight[项目反应理论(IRT)]
1. .grayLight[跨群组项目反应(MrP, GIRT, DCPO)]

???

鱼玄机《赠邻女》：羞日遮罗袖，愁春懒起妆。易求无价宝，难得有心郎

---

class: inverse, bottom

# 因素分析综述

---

## 因素分析模型(Factorial Models)

1. 探索性因子分析(EFA)
1. 验证性因子分析(CFA)
1. 结构方程模型(SEM)

---

### 理论

.navy[可见]指标(indicators) .red[&amp;larr;] 潜在变量

???

uncover the underlying structure of a relatively large set of variables. 

--

.pull-left[
### 操作

.red[Minimum] factors for the variances

a.k.a. 变量简化  
(降维打击？)
]

.pull-right[
&lt;img src="images/lv_jiangwei.jpg" height = 300 /&gt;
]

???

determine the minimum number of hypothetical factors or components that account for the variance between variables.

---

## Like...How?

.center[&lt;img src="images/lv_efa.png" height = 500 /&gt;]

???

Known: I wanna fewer variables
Unknown: how many? how to combine?

---

class: inverse, bottom

# 探索性因子分析
## Exploratory Factor Analysis

---

## 概念公式

.center[.large[**X&lt;sup&gt;*&lt;/sup&gt; = &amp;Phi;&amp;Lambda;' + &amp;delta;**]]


**X&lt;sup&gt;*&lt;/sup&gt;**: 潜在变量  
**&amp;Phi;**: 指标选择  
**&amp;Lambda;**: 单项贡献（a.k.a., factor loading）  
**&amp;delta;** 选择误差

???

Quinn, Kevin M. undefined/ed. “Bayesian Factor Analysis for Mixed Ordinal and Continuous Responses.” Political Analysis 12(4): 338–53.

---

## 一顿操作

1. 因子个数选择
1. 因子提取
1. Rotation
1. 因子合成
1. 结果检验

---

## 一个心理学案例

19,719 参与者, the "Big Five Personality" Test

变量名：

```
## race age engnat gender hand source country E1 E2 E3 E4 E5 E6 E7 E8 E9 E10 N1 N2 N3 N4 N5 N6 N7 N8 N9 N10 A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 O1 O2 O3 O4 O5 O6 O7 O8 O9 O10
```

???

经验开放性Openness, 尽责性Conscientiousness, 外向型Extraversion, 亲和性Agreeableness, 情绪不稳定型Neuroticism

https://quantdev.ssri.psu.edu/tutorials/intro-basic-exploratory-factor-analysis

---

## 因子个数选择

### 相关性分析

&lt;img src="03_latentVariableI_files/figure-html/corrplot-1.png" style="display: block; margin: auto;" /&gt;

---

### Horn's Parallel Analysis

已知观测数据集**O**&lt;sub&gt;m&amp;times;n&lt;/sub&gt;

1. 创建随机数据集**R**&lt;sub&gt;m&amp;times;n&lt;/sub&gt;;  
1. 相关矩阵&lt;sub&gt;**R**&lt;/sub&gt; 和 &amp;lambda;&lt;sub&gt;**R**&lt;/sub&gt;;  
1. 相关矩阵&lt;sub&gt;**Ok**&lt;/sub&gt; 和 &amp;lambda;&lt;sub&gt;**Ok**&lt;/sub&gt; (k为因子数)
1. &amp;lambda;&lt;sub&gt;**Ok**&lt;/sub&gt; vs. &amp;lambda;&lt;sub&gt;**R**&lt;/sub&gt;

A. 如果&amp;lambda;&lt;sub&gt;**Ok**&lt;/sub&gt; &lt; &amp;lambda;&lt;sub&gt;**R**&lt;/sub&gt;, 则 ~~k~~  
B. Kaiser criterion

???

&amp;lambda;是相关矩阵特征值
Kaiser criterion: 特征值&lt;1 不可

---

&lt;img src="03_latentVariableI_files/figure-html/parallelAnalysis-1.png" style="display: block; margin: auto;" /&gt;

---

## 因子提取(Factor Extraction)

+ .navy[Minimum residual (OLS)]
+ Principal axes
+ Alpha factoring
+ Weighted least squares
+ Minimum rank
+ .red[Maximum likelihood (ML, minimum &amp;chi;&lt;sup&gt;2&lt;/sup&gt; goodness of fit)]

---

## Rotation

.center[&lt;img src="images/lv_rotation.jpg" height = 530 /&gt;]

???
Rotation:

A pattern of loadings where each item loads strongly on only one of the factors, and much more weakly on the other factors.

---

## 简化数据结构

* Orthogonal: Varimax, quartimax, bentlerT, geominT, bifactor  
* .red[Oblique]: Oblimin, quartimin, simplimax, bentlerQ, geominQ, biquartimin


???

Orthogonal(正交)

优选Oblique，允许factor间correlate

---

## 因子合成


```
## 
## Loadings:
##     MR1    MR2    MR3    MR5   
## E1   0.691                     
## E2  -0.695                     
## E3   0.632                     
## E4  -0.720                     
## E5   0.723                     
## E6  -0.544                     
## E7   0.738                     
## E8  -0.596                     
## E9   0.639                     
## E10 -0.652                     
## N1          0.689              
## N2         -0.503              
## N3          0.614              
## N4         -0.297              
## N5          0.534              
## N6          0.747              
## N7          0.709              
## N8          0.741              
## N9          0.729              
## N10         0.579              
## A1                -0.438       
## A2                 0.501       
## A3                -0.407       
## A4                 0.800       
## A5                -0.658       
## A6                 0.607       
## A7                -0.602       
## A8                 0.575       
## A9                 0.696       
## A10                0.335       
## C1                        0.600
## C2                       -0.538
## C3                        0.401
## C4                       -0.532
## C5                        0.632
## C6                       -0.587
## C7                        0.557
## C8                       -0.451
## C9                        0.642
## C10                       0.471
## O1                             
## O2                             
## O3                             
## O4                             
## O5                             
## O6                             
## O7                             
## O8                             
## O9                             
## O10                            
##     MR4   
## E1        
## E2        
## E3        
## E4        
## E5        
## E6        
## E7        
## E8        
## E9        
## E10       
## N1        
## N2        
## N3        
## N4        
## N5        
## N6        
## N7        
## N8        
## N9        
## N10       
## A1        
## A2        
## A3        
## A4        
## A5        
## A6        
## A7        
## A8        
## A9        
## A10       
## C1        
## C2        
## C3        
## C4        
## C5        
## C6        
## C7        
## C8        
## C9        
## C10       
## O1   0.600
## O2  -0.555
## O3   0.531
## O4  -0.474
## O5   0.581
## O6  -0.491
## O7   0.489
## O8   0.565
## O9   0.350
## O10  0.661
## 
##                  MR1   MR2
## SS loadings    4.891 4.416
## Proportion Var 0.098 0.088
## Cumulative Var 0.098 0.186
##                  MR3   MR5
## SS loadings    3.617 3.183
## Proportion Var 0.072 0.064
## Cumulative Var 0.258 0.322
##                  MR4
## SS loadings    3.155
## Proportion Var 0.063
## Cumulative Var 0.385
```

---

## 诊断指标

1. Sum of squared (SS) loading&lt;sup&gt;1&lt;/sup&gt;
1. Communality &amp; Uniqueness
1. Root means square of residuals(RMSR)
1. Tucker-Lewis Indes (TLI)
1. Reliability test (Crobach's &amp;alpha;)&lt;sup&gt;2&lt;/sup&gt;

.footnote[
[1] 特征值  
[2] 为每个因子分别计算
]

???

SS：Kaiser criterion: &amp;lambda; &lt; 1 不可
Communality:  SS of all the factor loadings for a given variable
Uniqueness: 1 - Communality
RMSR &lt; 0.05
TLI &gt; 0.9

Crobach's &amp;alpha;: 计算因子分布的variables是不是内部一致，除非发表，不大必要

---


```
## Factor Analysis using method =  minres
## Call: fa(r = ., nfactors = 5, rotate = "oblimin", fm = "minres")
## Standardized loadings (pattern matrix) based upon correlation matrix
##       MR1   MR2   MR3   MR5
## E1   0.69  0.04 -0.03 -0.01
## E2  -0.70 -0.08 -0.04  0.04
## E3   0.63 -0.17  0.16  0.09
## E4  -0.72  0.05  0.04  0.00
## E5   0.72  0.03  0.12  0.07
## E6  -0.54  0.02 -0.08  0.00
## E7   0.74  0.00  0.06  0.02
## E8  -0.60 -0.04  0.11  0.07
## E9   0.64  0.05 -0.09 -0.02
## E10 -0.65  0.10  0.03  0.00
## N1  -0.06  0.69  0.10  0.05
## N2   0.07 -0.50 -0.01 -0.09
## N3  -0.12  0.61  0.20  0.10
## N4   0.13 -0.30 -0.06  0.07
## N5   0.01  0.53  0.01 -0.05
## N6   0.00  0.75  0.06 -0.01
## N7   0.06  0.71 -0.05 -0.08
## N8   0.05  0.74 -0.05 -0.08
## N9   0.03  0.73 -0.15  0.04
## N10 -0.21  0.58  0.02 -0.10
## A1   0.05  0.09 -0.44  0.02
## A2   0.28 -0.04  0.50 -0.05
## A3   0.17  0.27 -0.41 -0.15
## A4  -0.06  0.03  0.80  0.00
## A5  -0.06  0.04 -0.66  0.05
## A6  -0.05  0.13  0.61  0.02
## A7  -0.23  0.09 -0.60  0.05
## A8   0.05 -0.02  0.57  0.05
## A9   0.04  0.10  0.70  0.03
## A10  0.28 -0.08  0.33  0.11
## C1   0.02 -0.02 -0.04  0.60
## C2   0.05  0.04  0.08 -0.54
## C3  -0.08  0.05  0.07  0.40
## C4  -0.02  0.29  0.01 -0.53
## C5   0.08  0.00  0.01  0.63
## C6   0.01  0.10  0.05 -0.59
## C7  -0.06  0.14  0.00  0.56
## C8  -0.02  0.16 -0.11 -0.45
## C9   0.05  0.11  0.04  0.64
## C10  0.00  0.06  0.02  0.47
## O1  -0.03 -0.03 -0.04  0.02
## O2   0.07  0.22 -0.02  0.04
## O3  -0.02  0.10  0.07 -0.10
## O4   0.09  0.14 -0.12  0.11
## O5   0.15 -0.01 -0.06  0.14
## O6  -0.04  0.04 -0.08  0.07
## O7   0.02 -0.10 -0.03  0.17
## O8  -0.04  0.08 -0.11 -0.06
## O9  -0.19  0.15  0.20  0.04
## O10  0.13  0.02  0.00  0.02
##       MR4   h2   u2 com
## E1   0.00 0.46 0.54 1.0
## E2  -0.01 0.48 0.52 1.0
## E3  -0.06 0.57 0.43 1.3
## E4   0.03 0.52 0.48 1.0
## E5   0.03 0.60 0.40 1.1
## E6  -0.19 0.40 0.60 1.3
## E7  -0.01 0.57 0.43 1.0
## E8   0.00 0.33 0.67 1.1
## E9   0.09 0.40 0.60 1.1
## E10  0.01 0.45 0.55 1.1
## N1  -0.05 0.49 0.51 1.1
## N2   0.05 0.27 0.73 1.1
## N3   0.01 0.43 0.57 1.3
## N4  -0.07 0.14 0.86 1.8
## N5  -0.11 0.32 0.68 1.1
## N6  -0.07 0.57 0.43 1.0
## N7   0.02 0.52 0.48 1.1
## N8   0.01 0.57 0.43 1.0
## N9   0.00 0.54 0.46 1.1
## N10  0.08 0.47 0.53 1.4
## A1  -0.07 0.20 0.80 1.2
## A2   0.05 0.41 0.59 1.6
## A3   0.09 0.27 0.73 2.6
## A4  -0.01 0.62 0.38 1.0
## A5   0.00 0.45 0.55 1.0
## A6  -0.08 0.37 0.63 1.1
## A7  -0.01 0.50 0.50 1.4
## A8   0.02 0.36 0.64 1.0
## A9   0.04 0.51 0.49 1.1
## A10  0.06 0.31 0.69 2.4
## C1   0.12 0.39 0.61 1.1
## C2   0.12 0.31 0.69 1.2
## C3   0.27 0.24 0.76 2.0
## C4   0.02 0.45 0.55 1.6
## C5  -0.08 0.41 0.59 1.1
## C6   0.06 0.37 0.63 1.1
## C7   0.05 0.30 0.70 1.2
## C8  -0.03 0.30 0.70 1.4
## C9  -0.03 0.40 0.60 1.1
## C10  0.23 0.28 0.72 1.5
## O1   0.60 0.36 0.64 1.0
## O2  -0.56 0.36 0.64 1.3
## O3   0.53 0.30 0.70 1.2
## O4  -0.47 0.26 0.74 1.5
## O5   0.58 0.42 0.58 1.3
## O6  -0.49 0.27 0.73 1.1
## O7   0.49 0.30 0.70 1.3
## O8   0.56 0.32 0.68 1.2
## O9   0.35 0.19 0.81 2.7
## O10  0.66 0.48 0.52 1.1
## 
##                        MR1  MR2
## SS loadings           5.06 4.55
## Proportion Var        0.10 0.09
## Cumulative Var        0.10 0.19
## Proportion Explained  0.26 0.23
## Cumulative Proportion 0.26 0.49
##                        MR3  MR5
## SS loadings           3.72 3.27
## Proportion Var        0.07 0.07
## Cumulative Var        0.27 0.33
## Proportion Explained  0.19 0.16
## Cumulative Proportion 0.67 0.84
##                        MR4
## SS loadings           3.20
## Proportion Var        0.06
## Cumulative Var        0.40
## Proportion Explained  0.16
## Cumulative Proportion 1.00
## 
##  With factor correlations of 
##       MR1   MR2   MR3   MR5
## MR1  1.00 -0.24  0.25  0.09
## MR2 -0.24  1.00 -0.04 -0.24
## MR3  0.25 -0.04  1.00  0.14
## MR5  0.09 -0.24  0.14  1.00
## MR4  0.17 -0.08  0.07  0.05
##       MR4
## MR1  0.17
## MR2 -0.08
## MR3  0.07
## MR5  0.05
## MR4  1.00
## 
## Mean item complexity =  1.3
## Test of the hypothesis that 5 factors are sufficient.
## 
## The degrees of freedom for the null model are  1225  and the objective function was  19.12 with Chi Square of  376676
## The degrees of freedom for the model are 985  and the objective function was  3.01 
## 
## The root mean square of the residuals (RMSR) is  0.03 
## The df corrected root mean square of the residuals is  0.04 
## 
## The harmonic number of observations is  19718 with the empirical chi square  52912.5  with prob &lt;  0 
## The total number of observations was  19719  with Likelihood Chi Square =  59268.15  with prob &lt;  0 
## 
## Tucker Lewis Index of factoring reliability =  0.807
## RMSEA index =  0.055  and the 90 % confidence intervals are  0.054 0.055
## BIC =  49527.15
## Fit based upon off diagonal values = 0.97
## Measures of factor score adequacy             
##                                                    MR1
## Correlation of (regression) scores with factors   0.95
## Multiple R square of scores with factors          0.91
## Minimum correlation of possible factor scores     0.81
##                                                    MR2
## Correlation of (regression) scores with factors   0.95
## Multiple R square of scores with factors          0.90
## Minimum correlation of possible factor scores     0.79
##                                                    MR3
## Correlation of (regression) scores with factors   0.93
## Multiple R square of scores with factors          0.87
## Minimum correlation of possible factor scores     0.75
##                                                    MR5
## Correlation of (regression) scores with factors   0.91
## Multiple R square of scores with factors          0.84
## Minimum correlation of possible factor scores     0.67
##                                                    MR4
## Correlation of (regression) scores with factors   0.91
## Multiple R square of scores with factors          0.83
## Minimum correlation of possible factor scores     0.66
```

---

## 因子在哪里？

"score"

&lt;img src="03_latentVariableI_files/figure-html/scores-1.png" style="display: block; margin: auto;" /&gt;

---

## Principal Component Analysis

与EFA比肩的选择

--

.center[&lt;img src="images/lv_pca.png" height = 300 /&gt;]

.large[.center[C = w&lt;sub&gt;i&lt;/sub&gt;Y&lt;sub&gt;i&lt;/sub&gt;]]

???

create one or more index variables (Components) from a larger set of measured variables (Y)

---

## PCA vs. EFA

结果或近似，逻辑大不同（注意箭头方向！）

.center[&lt;img src="images/lv_pcaVsEfa.PNG" height = 400 /&gt;]

???
PCA: measurement to index   

write all variables in terms of a smaller set of features which allows for a maximum amount of variance to be retained in the data.   


EFA: indices to measurement (of a latent variable)   

find a set of features which allow for understanding as much of the correlations between measured variables as possible. individually.

---

## 怎么选

--

* PCA最大程度保留可见变量信息，EFA旨在提取不可变量特征；

--

* 当Variable之间关系不那么紧密或受同一变量影响，PCA &gt; EFA；

--

* 当估计潜在变量时，PCA可能夸大可见指标的影响

---

class: inverse, bottom

# 验证性因子分析
## Confirmative Factor Analysis

---


## 探索性 vs 验证性：实现

.left-column[
### EFA: 数据指向

1. 实证观察（归纳）
1. 未知维度
    + 每个维度都产生影响
1. 多重指标
    + Loading大小之分
1. 无视测量偏差关联
1. Underidentified

]

.right-column[
### CFA: 理论指向

1. 理论定义（演绎）
1. 明确维度
    + 维度-指标关系明确
1. 单一指标
    + Loading有无之分
1. 允许测量误差相关
1. 必须identifiable
]

---

## CFA 指标选择

1. 严格依据理论
1. 每维度一指标

--

### 例：人际信任

定义：.red[相信]他人不会.navy[伤害自己]或.navy[违背约定].

--

指标：
.small[
1. 总体而言，您是认同多数人是值得信任的，还是防人之心不可无？
1. 您认为多数时候人们是乐于助人的还是自私自利的？
1. 如果有机会，您认为别人是会占您便宜，还是说会恪守约定、公平行事？
]

---

## CFA 指标选择

操作原则：

1. 每个维度一个指标，但维度拆分.navy[艺术&gt;技术]

--

1. .red[~~原因~~]效果指标

--

<div id="htmlwidget-0d6bef35a720b035c456" style="width:504px;height:360px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-0d6bef35a720b035c456">{"x":{"diagram":"digraph {\n\ngraph[layout = dot]\n\nnode[shape = rectangle, style = filled, fillcolor = Linen]\n\ns [label = \"压力\", shape = \"ellipse\"]\nd [label = \"家人\n去世\"]\nj [label =  \"丢失\n工作\"]\ni [label = \"身患\n疾病\"]\n\n# edge definitions with the node IDs\ns -> {d, j, i}\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>


---

## 模型建构

.center[&lt;img src="images/lv_multitrait.png" height = 550 /&gt;]

???

裁判对滑雪运动员的评判

单侧: factor complexity = 1 （一个变量只贡献一个latent）  
双侧: factor complexity &gt; 1

---

## 定义公式

.center[.large[**X\* = &amp;Lambda;&lt;sub&gt;X&lt;/sub&gt;&amp;xi; + &amp;delta;**]]

**X**： 指标向量  
**&amp;xi;**：潜在变量  
**&amp;Lambda;&lt;sub&gt;X&lt;/sub&gt;**: X = f(&amp;xi;)系数(a.k.a., loading, path)  
**&amp;delta;**：偏误向量  

**&amp;Phi;**: 潜在变量的协方差矩阵  
**&amp;Theta;&lt;sub&gt;&amp;sigma;&lt;/sub&gt;**: 偏误的协方差矩阵

???

**&amp;xi;**: ksi  
**&amp;delta;**: delta  
**&amp;Phi;**: phi  
**&amp;Theta;&lt;sub&gt;&amp;sigma;&lt;/sub&gt;**: theta  

在EFA中潜在变量在等号左边，观测变量在右边

---

.center[&lt;img src="images/lv_partMultitraitpng.png" height = 300 /&gt;]

`$$\begin{bmatrix}x_1\\
x_2\\
x_3\\
x_4\\
x_5
\end{bmatrix} = \begin{bmatrix}1 &amp; 1 &amp; 0\\
\lambda_{21} &amp; 1 &amp; 0\\
\lambda_{31} &amp; 1 &amp; 0\\
\lambda_{41} &amp; 0 &amp; 1\\
\lambda_{51} &amp; 0 &amp; 1
\end{bmatrix} \begin{bmatrix}\xi_1\\
\xi_2\\
\xi_3
\end{bmatrix} + \begin{bmatrix}\delta_1\\
\delta_2\\
\delta_3\\
\delta_4\\
\delta_5
\end{bmatrix}$$`

---

潜在变量矩阵

**&amp;Phi;** = 
`\begin{bmatrix}
\phi_{11} &amp; &amp; \\
0 &amp; \phi_{22} &amp; \\
0 &amp; \phi_{23} &amp; \phi_{33}
\end{bmatrix}`


偏误矩阵

diag **&amp;Theta;&lt;sub&gt;&amp;sigma;&lt;/sub&gt;** = diag[var(&amp;delta;&lt;sub&gt;1&lt;/sub&gt;) var(&amp;delta;&lt;sub&gt;2&lt;/sub&gt;)...var(&amp;delta;&lt;sub&gt;5&lt;/sub&gt;)]

???

&amp;phi;23$: classical 和showy 裁判的相关性

---

## 你最多能连多少线？：Identification

`\begin{cases}
y = x + z\\
x = 2y - 3z
\end{cases}`

--

当**&amp;Lambda;、&amp;Phi;、&amp;Theta;**存在唯一解时，模型是identified.


&amp;Lambda;: `\(X = f(\xi)\)`系数(a.k.a., loading)  
&amp;Phi;: 潜在变量的协方差矩阵  
&amp;Theta; 偏误的协方差矩阵

--

**t rule**:

t &lt; q(q + 1)/2

t: 不可见
q：可见

???

Another way to calculate df.

---

为保证identifable， 要对CFA进行限制

1. Scaling
    + &amp;lambda;&lt;sub&gt;11&lt;/sub&gt; = 1;
    + 将潜在变量方差设为1(Standardized metric)
2. 参数调整
    + 特定因子loading设为0；
    + 偏误的协方差设为0；
    + 偏误的方差设为0；

---

## 解方程

**&amp;Sigma;**: 所有可见指标得协方差矩阵

.center[.large[**&amp;Sigma;(&amp;theta;) = &amp;Lambda;&lt;sub&gt;X&lt;/sub&gt;&amp;Phi;&amp;Lambda;&lt;sub&gt;X&lt;/sub&gt;' + &amp;Theta;&lt;sub&gt;&amp;delta;&lt;/sub&gt;**]]

.pull-left[
全信息估计：

Maximum likelihood:   
Generalized Least Squares  
Unweighted Least Squares
]

.pull-right[
有限信息估计：

Two Stage Least Squares

]

???

寻找最优**&amp;Sigma;**

---

## 常见问题
### Matrix to be analyzed not positive definite

+ Typo in data file or covariance matrix
+ Pairwise deletion of missing data
+ Perfect collinearity
+ Outliers/influential cases

---

### Improper solutions

+ Typo in program
+ Population value near the borderline combined with sampling fluctuation
+ Specification error
+ Small samples (&lt;150 or so) combined with 2 indicators per factor
+ “unlucky” sample
+ Outliers/influential cases

---

### Nonconvergence

+ Typo in program, data file, or covariance matrix
+ Underidentified model
+ Poor model specification
+ Bad starting values
+ Small samples (N&lt;100)
+ Only 2 indicators per factor
+ Outliers/influential cases
+ Observed variables in very different scale

---

## 结果诊断

### Overall: &amp;chi;&lt;sup&gt;2&lt;/sup&gt;

结果显著则说明整体模型可能有问题。

--

然而，当N足够大时&amp;chi;&lt;sup&gt;2&lt;/sup&gt;通常显著

???

1. Because models are almost always incorrect, any otherwise reasonably fitting model can be rejected when sample size is sufficient
1. Also a poor fitting model could be accepted if there is insufficient power to detect misspecification.

---

### Incremental Fit Indices

将模型与基线模型比较

???

基线模型：只保留可见变量的方差和协方差

--

#### Tucker-Lewis Index (TLI, &amp;rho;&lt;sub&gt;2&lt;/sub&gt;, Non-Normed Fit Index)

#### Comparative Fit Index (CFI)

+ 1 理想情况
+ &lt;.95 不可接受

???

CFI可以&gt;1, 这种情况视为1

---

### Absolute Fit Indices

#### Root Mean Square Error of Approximation (RMSEA)
#### Standardized Root Mean Square Residual (SRMR)

+ 0 理想情况
+ &amp;le; 0.05 不错
+ 0.05 ~ 0.08 差强人意
+ &amp;ge; 0.1 不可接受

---

## 实例：Holzinger &amp; Swineford 1939

.pull-left[
对初中生精神状况的调查：
+ 视觉因素：x&lt;sub&gt;1~3&lt;/sub&gt;
+ 阅读因素：x&lt;sub&gt;4~6&lt;/sub&gt;
+ 表达因素：x&lt;sub&gt;7~9&lt;/sub&gt;
]

.pull-right[
&lt;img src="03_latentVariableI_files/figure-html/diagram-cfa-1.png" style="display: block; margin: auto;" /&gt;
]

---


```
## lavaan 0.6-7 ended normally after 35 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of free parameters                         21
##                                                       
##   Number of observations                           301
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                85.306
##   Degrees of freedom                                24
##   P-value (Chi-square)                           0.000
## 
## Model Test Baseline Model:
## 
##   Test statistic                               918.852
##   Degrees of freedom                                36
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.931
##   Tucker-Lewis Index (TLI)                       0.896
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)              -3737.745
##   Loglikelihood unrestricted model (H1)      -3695.092
##                                                       
##   Akaike (AIC)                                7517.490
##   Bayesian (BIC)                              7595.339
##   Sample-size adjusted Bayesian (BIC)         7528.739
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.092
##   90 Percent confidence interval - lower         0.071
##   90 Percent confidence interval - upper         0.114
##   P-value RMSEA &lt;= 0.05                          0.001
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.065
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate
##   visual =~                
##     x1                1.000
##     x2                0.554
##     x3                0.729
##   textual =~               
##     x4                1.000
##     x5                1.113
##     x6                0.926
##   speed =~                 
##     x7                1.000
##     x8                1.180
##     x9                1.082
##   Std.Err  z-value  P(&gt;|z|)
##                            
##                            
##     0.100    5.554    0.000
##     0.109    6.685    0.000
##                            
##                            
##     0.065   17.014    0.000
##     0.055   16.703    0.000
##                            
##                            
##     0.165    7.152    0.000
##     0.151    7.155    0.000
## 
## Covariances:
##                    Estimate
##   visual ~~                
##     textual           0.408
##     speed             0.262
##   textual ~~               
##     speed             0.173
##   Std.Err  z-value  P(&gt;|z|)
##                            
##     0.074    5.552    0.000
##     0.056    4.660    0.000
##                            
##     0.049    3.518    0.000
## 
## Variances:
##                    Estimate
##    .x1                0.549
##    .x2                1.134
##    .x3                0.844
##    .x4                0.371
##    .x5                0.446
##    .x6                0.356
##    .x7                0.799
##    .x8                0.488
##    .x9                0.566
##     visual            0.809
##     textual           0.979
##     speed             0.384
##   Std.Err  z-value  P(&gt;|z|)
##     0.114    4.833    0.000
##     0.102   11.146    0.000
##     0.091    9.317    0.000
##     0.048    7.779    0.000
##     0.058    7.642    0.000
##     0.043    8.277    0.000
##     0.081    9.823    0.000
##     0.074    6.573    0.000
##     0.071    8.003    0.000
##     0.145    5.564    0.000
##     0.112    8.737    0.000
##     0.086    4.451    0.000
```

---

class: inverse, bottom

# 结构方程模型
## Structural Equation Model

---

## 结构方程模型

+ Structural equation models (SEMs)
+ LISREL (Linear Structural ReLationships) models
+ Covariance structure models
+ Latent variable models
+ Structural equations with latent variables

---

## “老朋友”

Confirmative factor analysis  
Multiple regression  
Multivariate regression  
ANOVA  
General linear model  
Path analysis  
Recursive models  
Dichotomous and ordered probit  
Seemingly unrelated regressions  
Simultaneous models  
Latent growth curve models  
......

---

## CFA之上

与CFA相比，SEM：

+ 观察变量： X, .red[Y]

--

+ 模型建构：
    1. Latent variable model
    1. Measurement model (CFA)
    1. Relations among the errors 
    
--

+ 依然要求identification

---

## 估计

MLE

--

## 诊断

+ Overall：&amp;chi;&lt;sup&gt;2&lt;/sup&gt;
+ Incremental：
    + TLI &amp; CLI
    + Incremental Fit Index(IFI, &amp;Delta;&lt;sup&gt;2&lt;/sup&gt;): 1理想，&lt;0.9不可接受
+ Absolute:
    + RMSEA: &lt; 0.06
    + BIC: 越小越好
    
---

实例：Bollen 1989

政治民主（1960，1965）与工业化

&lt;img src="03_latentVariableI_files/figure-html/diagram-sem-1.png" style="display: block; margin: auto;" /&gt;

---


```
## lavaan 0.6-7 ended normally after 68 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of free parameters                         31
##                                                       
##   Number of observations                            75
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                38.125
##   Degrees of freedom                                35
##   P-value (Chi-square)                           0.329
## 
## Model Test Baseline Model:
## 
##   Test statistic                               730.654
##   Degrees of freedom                                55
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.995
##   Tucker-Lewis Index (TLI)                       0.993
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)              -1547.791
##   Loglikelihood unrestricted model (H1)      -1528.728
##                                                       
##   Akaike (AIC)                                3157.582
##   Bayesian (BIC)                              3229.424
##   Sample-size adjusted Bayesian (BIC)         3131.720
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.035
##   90 Percent confidence interval - lower         0.000
##   90 Percent confidence interval - upper         0.092
##   P-value RMSEA &lt;= 0.05                          0.611
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.044
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate
##   ind60 =~                 
##     x1                1.000
##     x2                2.180
##     x3                1.819
##   dem60 =~                 
##     y1                1.000
##     y2                1.257
##     y3                1.058
##     y4                1.265
##   dem65 =~                 
##     y5                1.000
##     y6                1.186
##     y7                1.280
##     y8                1.266
##   Std.Err  z-value  P(&gt;|z|)
##                            
##                            
##     0.139   15.742    0.000
##     0.152   11.967    0.000
##                            
##                            
##     0.182    6.889    0.000
##     0.151    6.987    0.000
##     0.145    8.722    0.000
##                            
##                            
##     0.169    7.024    0.000
##     0.160    8.002    0.000
##     0.158    8.007    0.000
## 
## Regressions:
##                    Estimate
##   dem60 ~                  
##     ind60             1.483
##   dem65 ~                  
##     ind60             0.572
##     dem60             0.837
##   Std.Err  z-value  P(&gt;|z|)
##                            
##     0.399    3.715    0.000
##                            
##     0.221    2.586    0.010
##     0.098    8.514    0.000
## 
## Covariances:
##                    Estimate
##  .y1 ~~                    
##    .y5                0.624
##  .y2 ~~                    
##    .y4                1.313
##    .y6                2.153
##  .y3 ~~                    
##    .y7                0.795
##  .y4 ~~                    
##    .y8                0.348
##  .y6 ~~                    
##    .y8                1.356
##   Std.Err  z-value  P(&gt;|z|)
##                            
##     0.358    1.741    0.082
##                            
##     0.702    1.871    0.061
##     0.734    2.934    0.003
##                            
##     0.608    1.308    0.191
##                            
##     0.442    0.787    0.431
##                            
##     0.568    2.386    0.017
## 
## Variances:
##                    Estimate
##    .x1                0.082
##    .x2                0.120
##    .x3                0.467
##    .y1                1.891
##    .y2                7.373
##    .y3                5.067
##    .y4                3.148
##    .y5                2.351
##    .y6                4.954
##    .y7                3.431
##    .y8                3.254
##     ind60             0.448
##    .dem60             3.956
##    .dem65             0.172
##   Std.Err  z-value  P(&gt;|z|)
##     0.019    4.184    0.000
##     0.070    1.718    0.086
##     0.090    5.177    0.000
##     0.444    4.256    0.000
##     1.374    5.366    0.000
##     0.952    5.324    0.000
##     0.739    4.261    0.000
##     0.480    4.895    0.000
##     0.914    5.419    0.000
##     0.713    4.814    0.000
##     0.695    4.685    0.000
##     0.087    5.173    0.000
##     0.921    4.295    0.000
##     0.215    0.803    0.422
```

---

## SEM "骚操作"

1. SEM怎么对待Measurement errors
1. SEM怎么处理非线性变量(hint: GSEM)
1. SEM怎么对待群组效应
1. SEM如何处理缺失值(hint: 可能比MI还要好哦！)

--

.red[SEM 不能证明因果关系！！]

---

## 总结一下

* 潜在变量分析概述
    + .navy[因素分析]
    + 类型分析
* 什么是EFA
    + 探索性因子分析：通过loading找到潜在变量
    + EFA诊断：Kaiser‘s criterion, reliability
    + EFA vs. PCA: 结果相似，逻辑不同
* 什么是CFA
    + 验证性因子分析：检验潜在变量对于观察指标是否有影响
    + CFA诊断：&amp;chi;&lt;sup&gt;2&lt;/sup&gt;, TLI/CFI，RMSEA/SRMR
* SEM 入门
    + Latent + measurement models
    + 不能证明因果关系！
class: inverse, center, middle


---

class: inverse, middle, center

# Thank you!

&lt;i class="fa fa-envelope fa-lg"&gt;&lt;/i&gt;&amp;nbsp; [yuehu@tsinghua.edu.cn](mailto:yuehu@tsinghua.edu.cn) 

&lt;i class="fa fa-globe fa-lg"&gt;&lt;/i&gt;&amp;nbsp; https://sammo3182.github.io/

&lt;i class="fab fa-github fa-lg"&gt;&lt;/i&gt;&amp;nbsp; [sammo3182](https://github.com/sammo3182)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
