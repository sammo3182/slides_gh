---
title: "Case Illustration: Large-N Method"
subtitle: "Understanding Policies (10700193-90)"
author: "Yue Hu"
institute: "Tsinghua University" 
knitr: 
    opts_chunk:
      echo: false
format: 
  revealjs:
    css: https://www.drhuyue.site/slides_gh/css/style_basic.css
    theme: ../../../css/goldenBlack.scss
    slide-number: true
    # filters: [appExclusion.lua] # not count appendices into page number
    incremental: true
    preview-links: true # open an iframe for a link
    link-external-newwindow: true
    self-contained: false
    chalkboard: false # allwoing chalk board B, notes canvas C
    # callout-icon: false
    show-slide-number: all # `speaker` only print in pdf, `all` shows all the time
    title-slide-attributes:
      data-background-image: https://gitlab.com/sammo3182/backup/raw/85b3c1ad4b459d7a9f901f124b936428eda5fcaf/logo_THPS.png?inline=true
      data-background-size: 250px   
      data-background-position: top 10% right 5%
    default-image-extension: png
revealjs-plugins:
  - spotlight
lightbox: 
  match: auto
  effect: fade
spotlight:
  size: 50
  presentingCursor: default
  toggleSpotlightOnMouseDown: false
  spotlightOnKeyPressAndHold: 73 # keycode for "i"
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
if (!require(pacman)) install.packages("pacman")
library(pacman)

p_load(
  icons, 
  tidyverse,
  tinytable,
  modelsummary,
  dotwhisker
) # data wrangling # data wrangling

# Functions preload
set.seed(313)

# Visualization
theme_set(
  theme_minimal(base_size = 18)
)

theme_update(
  plot.title = element_text(size = 18), 
  axis.title = element_text(size = 22), 
  axis.text = element_text(size = 18)
)
```

## Overview

:::: {.columns}

::: {.column width="60%"}
+ What is a large-N analysis (LNA)
  + How large is large?
- Why LNA
  - Why NOT experiment
  - What do we look for from the LNA?

+ How
    + One
    + Two
    + More than two
:::

::: {.column width="40%"}
![](https://drhuyue.site:10002/sammo3182/figure/lar_econometrics.jpg){fig-align="center" height=400}

:::

::::


# What

## What's LNA

In lieu of "quantitative"...

:::{.fragment}
Large-[N]{.red}: Number of **observations**---not subjects, but trails

- How large? 10, 100, 1000, 10000?
    - > We don't know......   
    - > It depends......  
    - > The larger, the better!
:::


:::{.notes}
What's a å®šé‡ç ”ç©¶?

- å®šç»“æœçš„é‡
- å®šæ•°æ®çš„é‡
  - éƒ½æ˜¯é‡å—ï¼Ÿbinaryï¼Œcategoricalï¼Œ ordinary

Did you really å®šé‡ï¼Ÿ
:::



# Why

## Why Not Experiments?

:::: {.columns}

::: {.column width="50%"}
**Experiment is powerful!**

+ Excluding confounders
+ Clear outcomes
+ Clear causal chain
:::

::: {.column width="50%"}
### But

- [Difficult]{.red} to conduct
- [Difficult]{.red} to represent
- No "cool" methods
:::

::::

::: {.fragment .r-fit-text}
Alternative: [Quasi]{.grayLight}-experiment^[[*Collins Thesaurus*: Quasi- =  pseudo-, apparent, seeming, semi-, so-called, would-be.]{.fragment}]

- Fake assignment
:::


## Why Have to Be large

:::{.huge style="text-align:center"}
- Sufficient amount to    
[represent]{.red} the population
- Sufficient variance to    
[fake]{.red} the control-treatment structure
:::


## Representation


:::{.callout-important}
## *Law of Large Numbers*(LLN)

As the number of experiments (sample) increases, the ratio of outcomes will converge to the theoretical (population) average.
:::

- &rarr; A rule of thumb: 100

:::{.fragment .callout-important}
## *Central Limit Theorem*(CLT)

The sampling distribution of the sample means approaches a normal distribution as the sample size gets larger.
:::

- &rarr; A rule of thumb: 1000

<!-- ## Why normal -->

<!-- .pull-left[ -->
<!-- My highly-educated fellows, let's play a .blue[happy-happy] kid game! -->

<!-- And we are going outside! ğŸ˜ˆ -->

<!-- ] -->

<!-- .pull-right[ -->
<!-- ### Step 1: Toss a fair coin -->

<!-- + Head: 1 step to the .blue[&larr;] -->
<!-- + Tail: 1 step to the .red[&rarr;] -->

<!-- ### Step 2: Toss six times -->

<!-- ### Step 3: Going forward -->
<!-- ] -->

## Magic of CLT

{{< video https://drhuyue.site:10002/sammo3182/video/lar_normalDistribution_bbc.mp4 title="Normal by people" height=600 loading="eager" allowfullscreen>}}

## Why does CLT ask for over 1000

![](https://drhuyue.site:10002/sammo3182/figure/lar_largeNumber.gif){fig-align="center" height=200}

:::{.fragment .callout-tip}
## The larger the better? 

$$\text{Margin of Error (M.E.)} = Z \times \frac{S}{\sqrt n}.$$

| Sample Size (n) | Margin of Error (M.E.) |
|-----------------|------------------------|
| 200             | 7.1%                   |
| 1000            | 3.2%                   |
| 2000            | 2.2%                   |
| 4000            | 1.6%                   |
:::

:::{.notes}
To cut the margin of error in half, like from 3.2% down to 1.6%, you need four times as big of a sample, like going from 1000 to 4000 respondents. To cut the margin of error by a factor of five, you need 25 times as big of a sample
:::

# How

## Univariate analysis

:::: {.columns}

::: {.column width="60%"}
![](https://drhuyue.site:10002/sammo3182/figure/lar_tooManyCourses.jpg){fig-align="center" height=600}

:::{.notes}
Let's say we'll test a school policy of course management
:::
:::

::: {.column width="40%"}
```{r data}
showWatching <- tibble(Student_ID = paste0("202409", sample(1000:9000, size = 7)), Courses = c(9, 9, 12, 10, 8, 10, 15))

tt(showWatching)
```
:::

::::



## How to Describe a Variable

Given the courses students took: (9, 9, 12, 10, 8, 10, 15)

::: {.fragment .nonincremental}
+ Mean: $\frac{9 + 9 + 12 + 10 + 8 + 10 + 15}{7} \approx 11.$
+ Median: 8, 9, 9, [10]{.red}, 10, 12, 15
+ Mode: 8, [9]{.red}, [9]{.red}, [10]{.red}, [10]{.red}, 12, 15
:::

:::: {.columns}

::: {.column .fragment width="40%"}
*Which one is **the best**?*
:::

::: {.column .fragment width="60%"}
![How about this](https://drhuyue.site:10002/sammo3182/figure/desc_sheHulk.png){fig-align="center" height=400}
:::

::::

## Levels of Descriptive Statistics {.scrollable}

:::: {.columns}

::: {.column width="20%"}
- Number
- Statistics
- Plot
:::

::: {.column .fragment width="80%"}
:::{.small}
```{r descriptive}
df_descrptive <- select(mtcars, -am, -carb) |>
  mutate(across(where(~length(unique(.x)) == 2), as.logical),
         across(where(~length(unique(.x)) < 7 & !is.logical(.x)), as.factor))

datasummary_skim(df_descrptive)
```
:::
:::

::::


## Binary Analysis

:::{.r-stack}
```{r scatter}
#| fig-align: center
#| fig-height: 6

ggplot(mtcars, aes(wt, mpg)) +
  geom_point() +
  ggtitle("Relations between variables") +
  ylab("Mileage per Gallon") +
  xlab("Weight")
```

:::{.fragment}
```{r scatterMess}
#| fig-align: center
#| fig-height: 6

data(tobacco, package = "summarytools")

ggplot(tobacco, aes(age, cigs.per.day)) +
  geom_point() +
  ggtitle("How about...") +
  ylab("Cigrate per day") +
  xlab("Age")
```
:::

:::

## Multivariate Analysis

:::{.r-stack}
![](https://drhuyue.site:10002/sammo3182/figure/lar_buyerSeller.jpg){fig-align="center" height=600}

![](https://drhuyue.site:10002/sammo3182/figure/lar_matching.png){.fragment fig-align="center" height=600}

![](https://drhuyue.site:10002/sammo3182/figure/lar_fitOLS.png){.fragment fig-align="center" height=600}
:::


## Controls are not a panacea

{{< video https://drhuyue.site:10002/sammo3182/video/lar_pork.mp4 title="Predicting Pork Price" height=600 loading="eager" allowfullscreen>}}

## The nature of LLN in public policy analysis

:::{.large}
> [ä»»ä½•æ”¿ç­–éƒ½å»ºç«‹åœ¨å¯¹äº‹ç‰©å·®å¼‚æ€§çš„åˆ†æå’ŒæŠŠæ¡ä¹‹ä¸Šï¼Œ**æ²¡æœ‰å·®å¼‚æ€§å°±æ²¡æœ‰æ”¿ç­–**ã€‚æˆ‘å›½ç¤¾ä¼šå·®å¼‚æ€§ç‰¹å¾æ˜æ˜¾ï¼Œåæ˜ åœ¨åœ°åŸŸã€åŸä¹¡ã€æ°‘æ—ã€äººç¾¤ç­‰å¤šä¸ªå±‚é¢ã€‚æˆ‘ä»¬çš„å†³ç­–éƒ¨ç½²æœ‰ç»¼åˆæ€§çš„ï¼Œä¹Ÿæœ‰ä¸“é¡¹æ€§çš„â€¦â€¦è¿™äº›éƒ½éœ€è¦å……åˆ†ç†Ÿæ‚‰æƒ…å†µã€æ·±å…¥åˆ†æè®ºè¯ã€ç§‘å­¦æŠŠæ¡å°ºåº¦ã€‚è¦åšæŒç§‘å­¦å†³ç­–ã€æ°‘ä¸»å†³ç­–ã€ä¾æ³•å†³ç­–ï¼Œå¯¹æƒ…å†µè¿›è¡Œæ·±å…¥åˆ†æã€‚]{.red}
:::

:::{style="text-align:right"}
--- ä¹ è¿‘å¹³ (ã€Šä¸­å¤®æ”¿æ²»å±€çš„åŒå¿—å¿…é¡»æœ‰å¾ˆå¼ºçš„çœ‹é½æ„è¯†ã€‹, 2015å¹´12æœˆ)
:::



## Present your model correctly

```{r dotwhisker}
#| fig-align: center
#| fig-height: 7

m1 <- lm(mpg ~ wt + cyl + disp + gear, data = mtcars)
m2 <- update(m1, . ~ . + hp) # add another predictor
m3 <- update(m2, . ~ . + am) # and another

list(m1, m2, m3) |>
  dwplot(
    show_stats = TRUE,
    vline = geom_vline(
      xintercept = 0,
      colour = "grey60",
      linetype = 2
    )
  )

```



## Take-Home Points

:::: {.columns}

::: {.column width="50%"}
+ What: "Quantitative" analysis
  + How large is large?
    + LLN: 100
    + CLT: 1000
- Why
  - Why Not experiment?
  - What do we look for from the LNA?
    - Average and distribution
+ How 
    + Univariate
    + Bivariate
    + Multivariate
:::

::: {.column .fragment width="50%"}
*Bonus: If you wanna know more*

[["æ²»ç†æŠ€æœ¯ä¸“é¢˜ï¼šæ”¿æ²»æ•°æ®åˆ†æ" (70700173)]{.green} ğŸ˜‹]{.large}
:::

::::
