---
title: "Population and Distrations"
subtitle: "Large N & Leeuwenhoek (70700173)"
author: "Yue Hu"
institution: "Tsinghua University"
# date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    self_contained: FALSE
    chakra: libs/remark-latest.min.js
    css: 
      - default
      - zh-CN_custom.css
      - style_ui.css
    nature:
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
      ratio: 16:9
---

What's distribution?

--

(Probability) distribution: 

The mathematical .red[function] that gives the probabilities of occurrence of different possible .red[outcomes] for an .red[experiment].

## Overview

1. Properties of distribution
1. Common kinds of distributions
1. Expectation

---

class: inverse, bottom

# Properties of Distributions

---

## Probability Distribution

* Probability Mass Function (PMF): Discrete (How to visualize it?)

???

A histogram

--

* Probability Density Function (PDF): Continuous
    + Cumulative density function: $F(x) = P(X < x)$

???

Draw a density plot

--

.center[<img src="images/dist_pmfPdf.png" height = 350 />]

---

## Moments of Probability Distribution

Specific quantitative measures of .red[the shape] of a function (?).

???

A function is a distribution: a distribution is event happening trajectory, a movement

--

.pull-left[

Physics

+ 0th: Total mass
+ 1st: Center of mass
+ 2ed: Rotational inertia

<img src = "images/dist_rotation.gif">

]

???

Rotational inertia: æƒ¯æ€§çŸ©

--

.pull-right[
Statistics

.center[<img src="images/dist_moments.png" height="350"/>]

]

???

+ 0th: Total probability
+ 1st: Mean
+ 2ed: Variance
+ 3id: Skewness
+ 4th: Kurtosis (tailedness)

Kurtosisï¼šå°–é”ç¨‹åº¦

---

## Properties of PMF/PDF

.pull-left[

<img src = "../mathCamp/images/math_integral.gif" height = 250>

None-negative

Total area = $\int^{+\infty}_{-\infty}f(x)dx = 1.$

]

.pull-right[

$P(x = c) = \int^c_cf(x)dx = 0.$

$$\begin{aligned}P(a\leq x \leq b) =& \int^b_af(x)x,\\
=& \int^b_{-\infty}f(x)dx -\\
 &\int^a_{-\infty}f(x)dx.
\end{aligned}$$

CDF: 

$P(X\leq x)$, PDF = $\frac{\partial CDF}{\partial X}.$

]

???

å¯¼æ•°æ˜¯æ–œç‡ï¼Œå³åœ¨æŸä¸€ç‚¹å‡½æ•°å˜åŒ–çš„åŠ é€Ÿåº¦ï¼›
åå¯¼æ•°æ˜¯æŠŠäºŒå…ƒå‡½æ•°çš„ä¸€ä¸ªè‡ªå˜é‡ä¸å˜ï¼Œå¦ä¸€ä¸ªæ­£å¸¸æ±‚å¯¼ï¼Œå°±åˆ†åˆ«æƒ³è±¡æˆzå¯¹xï¼Œyçš„å‡½æ•°ã€‚

https://www.zhihu.com/question/276405042#:~:text=%E5%81%8F%E5%AF%BC%E6%95%B0%E5%B0%B1%E6%98%AF%E5%90%AB%E6%9C%89%E5%A4%9A,%E5%BC%95%E8%B5%B7%E5%87%BD%E6%95%B0%E7%9A%84%E6%80%BB%E5%8F%98%E5%8C%96%E3%80%82

---

class: inverse, bottom

# Common Kinds of Distribution

---

## Basic Distributions

+ Binomial (discrete)
+ Poisson (discrete)
+ Uniform (continuous)
+ Normal (continuous)


---

## Bernoulli &larr; Binomial


Bernoulli: $k\in 0, 1,$ p is P(X = 1)
CDF: 
$$F = \begin{cases}
0, if\ k<0,\\
1 - p, if\ k \in[0, 1),\\
1, if\ k \geq 1.
\end{cases}$$

--

.pull-left[

PMF: 

$$f(k;p) = p^k(1 - p)^{1 - k}$$

+ &mu; = p
+ &sigma;<sup>2</sup> = p(1 - p)<sup>\*</sup>

]

.pull-right[

<img src="images/dist_bernoulli_pmf.gif" height="300"/>

]

.footnote[<sup>\*</sup> Population &sigma;<sup>2</sup> = &pi;(1 - &pi;).]

???

why pmf? Discrete

When we talk about how to describe a variable, we talked about this &pi;(1 - &pi;).

---

## Binomial distribution

.pull-left[
PDF: $f(k; n, p) = {n \choose k}p^k(1 - p)^{n - k}$

+ n, number of trials; 
+ p, the success probability in each trial; 
+ k, the number of success
+ ${n \choose k} = \frac{n!}{k!(n - k)!}$ (what's this?)

&mu; = np    
&sigma;<sup>2</sup> = np(1 - p)

]

???

Combination: no order, every draw is independent

--

.pull-right[
.center[<img src="images/dist_binomial_pdf.png" height="500"/>]
]

---

## How Does the Binomal Distribution Help in Social Science Research

A university hired 100 faculty members in a year, 25 female and 75 male. 
Given that the general hired ratio is 4:6 for women:men, what's the chance that the employment is fair in terms of gender equality?

$$PDF = {n \choose r}\pi^r(1 - \pi)^{n - r}$$

--

Let's .red[assume] the employment of any faculty member does not affect the chance the others are hired.

$$P(25) = {100 \choose 25}0.4^{25}(1 - 0.4)^{75} = 0.0006.$$

--

Very unlikely.

---

## Poisson Distribution

.pull-left[
PMF:
$Pr(X{=}k)= \frac{\lambda^k e^{-\lambda}}{k!},$

k is the number of occurrences

&mu; = &lambda;;    
&sigma;<sup>2</sup> = &lambda;.
]

--

.pull-right[
<img src = "images/dist_poisson.gif" height = 500>
]

---

## Uniform Distribution

CDF: 
$$F = \begin{cases}
0, if\ x < a,\\
\frac{x - a}{b - a}, if\ x \in[a, b),\\
1, if\ x \geq b.
\end{cases}$$


PDF:

$$f(x) = \begin{cases} 1/(b - a), if\ x \in [a, b],\\ 0, otherwise.\end{cases}$$

???

PDFå’ŒCDFå…³ç³»

$P(X\leq x)$, PDF = $\frac{\partial CDF}{\partial X}.$

---

.pull-left[

CDF: 
.center[<img src="images/dist_uniform_cdf.png" height="500"/>]
]

.pull-right[
PDF:
.center[<img src="images/dist_uniform_pdf.png" height="500"/>]
]

---

## Moments of Uniform Distribution

.pull-left[
+ &mu;

$$\begin{align}
\mu =& \int^b_a x \frac{1}{b - a} dx, \\
=& \frac{1}{b - a}\int^b_axdx, \\
=& \frac{1}{b - a}\frac{x^2}{2}|^b_a, \\
=& \frac{b^2 - a^2}{2(b - a)}, \\
=& \frac{a + b}{2}.
\end{align}$$
]

.pull-right[
+ &sigma;<sup>2</sup>

$$\begin{align}
\sigma^2 =& \sum x^2p(x) - \mu^2, \\
=& \int^b_ax^2\frac{1}{b - a}dx - (\frac{a + b}{2})^2, \\
=& \frac{1}{b - a}\int^b_ax^2dx - (\frac{a + b}{2})^2,\\
=& \frac{1}{b - a}\frac{x^3}{3}|^b_a - (\frac{a + b}{2})^2,\\
=& \frac{b^3 - a^3}{3(b - a)} - (\frac{a + b}{2})^2 = \frac{(b - a)^2}{12}.
\end{align}$$
]

???

$$\begin{align}
(b - a)^3 =& b^3 - 3b^2a + 3a^2b - 3a^3\\
\Rightarrow b^3 - a^3 =& (b - a)^3 + (3b^2a - 3a^2b),\\
=&(b - a)[(b - a)^2 + 3ba].\\

\therefore\frac{b^3 - a^3}{3(b - a)} - (\frac{a + b}{2})^2 =& \frac{(b - a)[(b - a)^2 + 3ba]}{3(b - a)} - \frac{(a + b)^2}{4},\\
=& \frac{4[(b - a)^2 + 3ba] - 3(a + b)^2}{12},\\
=& \frac{4b^2 + 4ab + 4a^2 - 3b^2 - 3a^2 - 6ab}{12},\\
=& \frac{b^2 - 2ab + a^2}{12} = \frac{(b - a)^2}{12}.
\end{align}$$

---

## Normal Distribution: Gaussian curve

PDF: 

$f(x) = \varphi(\frac{x - \mu}{\sigma}) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x - \mu)^2}{2\sigma^2}}.$

When &mu; = 1; &sigma;<sup>2</Sup> = 0, standard normal distribution.

???

ä¸˜æˆæ¡(1949)è¢«èª‰ä¸ºæ•°å­¦çš‡å¸ï¼Œé«˜æ–¯(1777)è¢«èª‰ä¸ºæ•°å­¦ç‹å­, è¯´é«˜æ–¯æ˜¯æ•°å­¦ç‹å­ï¼Œæ„æ€ä¸æ˜¯é«˜æ–¯ä¹‹ä¸Šè¿˜æœ‰è¿™ä¸ªç‹é‚£ä¸ªç‹ï¼Œè€Œæ˜¯æŠŠæ•°å­¦æ¯”ä½œç‹ã€‚æ•°å­¦æ˜¯ç‹ï¼Œé«˜æ–¯æ˜¯ç‹å­.

--

.pull-left[
.red[Z Score:]

$Z = \frac{x - \mu}{\sigma}$ &rarr; $f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(z)^2}{2}}$
]

--

.pull-right[
.center[<img src = "images/dist_zscoreNormal.gif" height = 300>]
]

???

Knowing Z-score, one can calculate the probability of it accordingly

---

## How to Use

Known that the average IQ in the U.S. is 100, standard deviation is 16, what's the probability a US citizen's IQ is higher than 125 or lower than 85?

--

.center[
$Z_1 = \frac{125 - 100}{16} = 1.056$

$Z_2 = \frac{85 - 100}{16} = -0.9375$
]

---

## Z-Score &rarr; Probability

.left-column[
### Old days
]

.right-column[
.center[<img src="images/dist_zScore.gif" height="500"/>]
]

---

## Z-Score &rarr; Probability

.left-column[
### Old days
### Cool kids
]

.right-column[
Using R:

`pnorm(<Z-score>)`

P(X &ge; 125) = `1 - pnorm(1.056)` = `r 1 - pnorm(1.056)`

P(X < 85) = `pnorm(-0.9375)` = `r pnorm(-0.9375)`

]

--

.red[Hint]: p-value is $P(z\leq x)$.

---

class: inverse, bottom

# Expectation

---

## Calculating Expectations

"What would you guess if asking you the chance of heads to toss a coin?"

--

1. &mu; = E(X) = &sum; xp(x)
2. &sigma;<sup>2</sup> = E(x - &mu;)<sup>2</sup> = &sum; (x - &mu;)<sup>2</sup>p(x)

--

*Rule of expectation*

1. E(aX + bY + c) = aE(X) + bE(Y) + c;
2. var(aX + bY) = a<sup>2</sup>var(x) + b<sup>2</sup>var(y) + 2ab&bull;cov(x, y)

---

### Application

X is the reward generator of a paid module of a video game, the seed of which is based on tossing a fair dice (ğŸ˜‘).
When the dice is tossed, the reward is produced following this function: g(X) = 2 + 3X.

What's the expectation of rewards "ke-jin" players can get by purchasing this module?

$$E(X) = \sum xp(x) = 1\times\frac{1}{6} + 2\times\frac{1}{6} +\dots+6\times\frac{1}{6} = 3.5.$$

Then $$E(g(x)) = E(2 + 3X) = 2 + 3\times 3.5 = 12.5.$$

---

## Wrap Up

.pull-left[
### Describing a Distribution

+ PDF/PMF
+ CDF
+ Moments

### Common Distributions

+ Binomial
+ Uniform
+ Normal
]

.pull-right[

### Expectation

+ Definition
+ Rules

]

---

## Bonus

.pull-left[
Jacob Bernoulli&Gerolamo Cardano
.center[
<img src = "images/dist_Jakob_Bernoulli.jpg" height = 200 width = 160 class="rounded-corners">
<img src = "images/dist_Cardano.jpg" height = 200  width = 160 class="rounded-corners">
]
]

.pull-right[
.center[
SimÃ©on Poisson   
<img src = "images/dist_Poisson.jpg" height = 200  width = 160 class="rounded-corners">
]
]

.center[
Clarl F. Gauss   
<img src = "images/dist_Gauss.jpg" height = 200 width = 300 class="rounded-corners">
]

???
Bernoulli is discovered by Jacob, who also invented mathematical constant e.

Cardano defined uniform in the 16th century, "æ„å¤§åˆ©æ–‡è‰ºå¤å…´æ—¶æœŸç™¾ç§‘å…¨ä¹¦å¼çš„å­¦è€…ï¼Œ æ•°å­¦å®¶ã€ç‰©ç†å­¦å®¶ã€å æ˜Ÿå®¶ã€å“²å­¦å®¶å’ŒèµŒå¾’ï¼Œå¤å…¸æ¦‚ç‡è®ºåˆ›å§‹äºº"


```{r pdfPrinting, eval = FALSE, include = FALSE}
pagedown::chrome_print(list.files(pattern = "04_.*.html"), 
                       timeout = 500, 
                       box_model = "padding")
```