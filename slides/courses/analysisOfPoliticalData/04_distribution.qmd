---
title: "Population and Distribution"
subtitle: "Large N & Leeuwenhoek (70700173)"

author: "Yue Hu"

knitr: 
    opts_chunk: 
      echo: false

format: 
  revealjs:
    number-sections: true
    css: https://sammo3182.github.io/slides_gh/css/style_basic.css
    theme: ../../../css/goldenBlack.scss
    # logo: https://gitlab.com/sammo3182/backup/raw/85b3c1ad4b459d7a9f901f124b936428eda5fcaf/logo_zzxx.png?inline=true
    slide-number: true
    incremental: true
    preview-links: false # open an iframe for a link
    link-external-newwindow: true
    self-contained: false
    chalkboard: true # allwoing chalk board B, notes canvas C
    # callout-icon: false
    
    show-slide-number: all # `speaker` only print in pdf, `all` shows all the time
    title-slide-attributes:
      data-background-image: https://gitlab.com/sammo3182/backup/raw/85b3c1ad4b459d7a9f901f124b936428eda5fcaf/logo_THPS.png?inline=true
      data-background-size: 250px   
      data-background-position: top 10% right 5%

revealjs-plugins:
  - spotlight

# lightbox: auto
spotlight:
  size: 50
  presentingCursor: default
  toggleSpotlightOnMouseDown: false
  spotlightOnKeyPressAndHold: 73 # keycode for "i"
---

## Open Question

::: {.r-fit-text}
Why does Dr. Hu almost always "sacrifice" the programming teaching?

Options:

- He's not good at it
- It's too easy for teaching
- It's worthless to learn programming
- It's frustrated to teach programming
:::



## Overview {.unnumbered .nonincremental}

1. Properties of distributions
1. Types of distributions
1. Distribution &rarr; Prediction


# Properties of distributions

## (Probability) distribution

:::{.fragment .fade-in-then-semi-out}
> The mathematical [function]{.red} that gives the probabilities of occurrence of different possible outcomes for an experiment.

:::

::::{.columns}
:::{.column width="50%" .fragment}
![](https://drhuyue.site:10002/sammo3182/figure/dist_packageInsert.jfif){height=500 fig-align="center"}
:::

:::{.column width="50%" .fragment}
- Probability Mass Function (PMF): 
    - Discrete
    - Histogram
- Probability Density Function (PDF): 
    - Continuous
    - Density plot
- Cumulative density function (CDF): $F(x) = P(X \leq x) = \int_{-\infty}^{x} f(t) \, dt$
:::
::::

## Integral![](https://drhuyue.site:10002/sammo3182/figure/ci_fsmrof.png){height=30} 

:::{.r-stack}
![](https://drhuyue.site:10002/sammo3182/figure/dist_integral.jpg){fig-align="center" height=600}

![](https://drhuyue.site:10002/sammo3182/figure/dist_integral.webp){.fragment fig-align="center" height=500}
:::

## PDF and CDF

:::{.r-stack}
![](https://drhuyue.site:10002/sammo3182/figure/dist_integral.gif){fig-align="center" height=600}

![](https://drhuyue.site:10002/sammo3182/figure/dist_pmfPdf.png){.fragment fig-align="center" height=5\600}
:::


## Properties of PMF/PDF

- None-negative
- Total area = $\int^{+\infty}_{-\infty}f(x)dx = 1.$

- $P(x = c) = \int^c_cf(x)dx = 0.$

- $$P(a\leq x \leq b) = \int^b_af(x)x = \int^b_{-\infty}f(x)dx -\int^a_{-\infty}f(x)dx.$$

- CDF: $P(X\leq x)$, PDF = $\frac{\partial CDF}{\partial X}.$


:::{.notes}

å¯¼æ•°æ˜¯æ–œç‡ï¼Œå³åœ¨æŸä¸€ç‚¹å‡½æ•°å˜åŒ–çš„åŠ é€Ÿåº¦ï¼›
åå¯¼æ•°æ˜¯æŠŠäºŒå…ƒå‡½æ•°çš„ä¸€ä¸ªè‡ªå˜é‡ä¸å˜ï¼Œå¦ä¸€ä¸ªæ­£å¸¸æ±‚å¯¼ï¼Œå°±åˆ†åˆ«æƒ³è±¡æˆzå¯¹xï¼Œyçš„å‡½æ•°ã€‚

https://www.zhihu.com/question/276405042#:~:text=%E5%81%8F%E5%AF%BC%E6%95%B0%E5%B0%B1%E6%98%AF%E5%90%AB%E6%9C%89%E5%A4%9A,%E5%BC%95%E8%B5%B7%E5%87%BD%E6%95%B0%E7%9A%84%E6%80%BB%E5%8F%98%E5%8C%96%E3%80%82
:::

:::{.callout-note}
## [Rules of derivative](https://www.mathsisfun.com/calculus/derivatives-rules.html)

:::{style="text-align:center"}
- Power ~
- Sum ~
- Product ~
:::

:::



## Partial derivative ![](https://drhuyue.site:10002/sammo3182/figure/ci_fsmrof.png){height=30} 

![](https://drhuyue.site:10002/sammo3182/figure/dist_partialDerivative.png){fig-align="center" height=600}

## Describe a distribution: Say hello to moments, again

> **Moments**: Specific quantitative measures of [the shape]{.red} of a function.

::::{.columns}
:::{.column width="50%" .fragment}
*Physics*

+ 0th: Total mass
+ 1st: Center of mass
+ 2ed: Rotational inertia

:::{.fragment}
![](https://drhuyue.site:10002/sammo3182/figure/dist_rotation.gif){height=260}
:::
:::

:::{.notes}
Rotational inertia: æƒ¯æ€§çŸ©
:::

:::{.column width="50%" .fragment}
*Statistics*

![](https://drhuyue.site:10002/sammo3182/figure/dist_moments.png){height=400}
:::
::::


:::{.notes}
+ 0th: Total probability
+ 1st: Mean
+ 2ed: Variance
+ 3id: Skewness
+ 4th: Kurtosis (tailedness)

Kurtosisï¼šå°–é”ç¨‹åº¦, can be used to test prositivity assumption in causal inference, (Ratkovic 2023)
:::

## About Means ![](https://drhuyue.site:10002/sammo3182/figure/ci_fsmrof.png){.lightbox fig-align="center" height=30}

- **Arithmetic Mean (AM)**:
   - $$\bar{x} = \frac{x_1 + x_2 + x_3 + \ldots + x_n}{n} = \frac{\sum x_i}{n}$$
- **Geometric Mean (GM)**:
   - $$GM = \left( x_1 \cdot x_2 \cdot x_3 \cdot \ldots \cdot x_n \right)^{\frac{1}{n}} = \left( \prod x_i \right)^{\frac{1}{n}}$$
- **Harmonic Mean (HM)**:
   - $$HM = \frac{n}{\left(\frac{1}{x_1} + \frac{1}{x_2} + \frac{1}{x_3} + \ldots + \frac{1}{x_n}\right)} = \frac{n}{\sum \left(\frac{1}{x_i}\right)}$$
   - A special type of weighted mean

:::{.notes}
ç»å…¸çš„ä¾‹å­æ˜¯ä»¥ä¸åŒçš„é€Ÿåº¦é€šè¿‡ç›¸åŒçš„è·ç¦»ã€‚

è€ƒè™‘ä¸€æ¬¡å»ä¾¿åˆ©åº—å¹¶è¿”å›çš„è¡Œç¨‹ï¼š

å»ç¨‹é€Ÿåº¦ä¸º30 mph
è¿”ç¨‹æ—¶äº¤é€šæœ‰ä¸€äº›æ‹¥å µï¼Œæ‰€ä»¥é€Ÿåº¦ä¸º10 mph
å»ç¨‹å’Œè¿”ç¨‹èµ°çš„æ˜¯åŒä¸€è·¯çº¿ï¼Œä¹Ÿå°±æ˜¯è¯´è·ç¦»ä¸€æ ·ï¼ˆ5è‹±é‡Œï¼‰
æ•´ä¸ªè¡Œç¨‹çš„å¹³å‡é€Ÿåº¦æ˜¯å¤šå°‘ï¼Ÿ

å¦‚æœä¸å‡æ€ç´¢åœ°åº”ç”¨ç®—æœ¯å¹³å‡æ•°çš„è¯ï¼Œç»“æœæ˜¯20 mphï¼ˆ(30+10)/2ï¼‰ã€‚

ä½†æ˜¯è¿™ä¹ˆç®—ä¸å¯¹ã€‚å› ä¸ºå»ç¨‹é€Ÿåº¦æ›´å¿«ï¼Œæ‰€ä»¥ä½ æ›´å¿«åœ°å®Œæˆäº†å»ç¨‹çš„5è‹±é‡Œï¼Œæ•´ä¸ªè¡Œç¨‹ä¸­ä»¥30 mphçš„é€Ÿåº¦è¡Œé©¶çš„æ—¶é—´æ›´å°‘ï¼Œä»¥10 mphçš„é€Ÿåº¦è¡Œé©¶çš„æ—¶é—´æ›´å¤šï¼Œæ‰€ä»¥æ•´ä¸ªè¡Œç¨‹æœŸé—´ä½ çš„å¹³å‡é€Ÿåº¦ä¸ä¼šæ˜¯30 mphå’Œ10 mphçš„ä¸­ç‚¹ï¼Œè€Œåº”è¯¥æ›´æ¥è¿‘10 mphã€‚

ä¸ºäº†æ­£ç¡®åœ°åº”ç”¨ç®—æœ¯å¹³å‡æ•°ï¼Œæˆ‘ä»¬éœ€è¦åˆ¤å®šä»¥æ¯ç§é€Ÿç‡è¡Œé©¶æ‰€èŠ±çš„æ—¶é—´ï¼Œç„¶åä»¥é€‚å½“çš„æƒé‡åŠ æƒç®—æœ¯å¹³å‡æ•°çš„è®¡ç®—ï¼š

å»ç¨‹ï¼š 5 / (30/60) = 10åˆ†é’Ÿ
è¿”ç¨‹ï¼š 5 / (10/60) = 30 åˆ†é’Ÿ
æ€»è¡Œç¨‹ï¼š 10 + 30 = 40åˆ†é’Ÿ
åŠ æƒç®—æœ¯å¹³å‡æ•°ï¼š (30 * 10/40) + (10 * 30/40) = 15 mph
æ‰€ä»¥ï¼Œæˆ‘ä»¬çœ‹åˆ°ï¼ŒçœŸæ­£çš„å¹³å‡é€Ÿåº¦æ˜¯15 mphï¼Œæ¯”ä½¿ç”¨æœªåŠ æƒçš„ç®—æœ¯å¹³å‡æ•°è®¡ç®—æ‰€å¾—ä½äº†5 mphï¼ˆæˆ–è€…25%ï¼‰ã€‚

é‚£å¦‚æœç”¨è°ƒå’Œå¹³å‡æ•°å‘¢ï¼Ÿ

2 / (1/30 + 1/10) = 15

ä¸€ä¸‹å­å¾—åˆ°äº†çœŸæ­£çš„è¡Œç¨‹å¹³å‡é€Ÿåº¦ï¼Œè‡ªåŠ¨æ ¹æ®åœ¨æ¯ä¸ªæ–¹å‘ä¸Šä½¿ç”¨çš„æ—¶é—´è¿›è¡Œè°ƒæ•´ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œä¹‹æ‰€ä»¥å¯ä»¥ç›´æ¥åº”ç”¨è°ƒå’Œå¹³å‡æ•°ï¼Œæ˜¯å› ä¸ºå»ç¨‹å’Œè¿”ç¨‹çš„è·ç¦»æ˜¯ç›¸ç­‰çš„ï¼Œå¦‚æœä¸¤è€…è·ç¦»ä¸ç­‰ï¼ˆæ¯”å¦‚å»ç¨‹å’Œè¿”ç¨‹èµ°äº†ä¸åŒè·¯çº¿ï¼‰ï¼Œé‚£ä¹ˆéœ€è¦åº”ç”¨åŠ æƒè°ƒå’Œå¹³å‡æ•°ã€‚

åœ¨è´¢ç»ä¸Šï¼ŒåŠ æƒè°ƒå’Œå¹³å‡æ•°å¯ä»¥ç”¨äºè®¡ç®—ç»„åˆæŠ•èµ„å¤šä¸ªè‚¡ç¥¨çš„å¸‚ç›ˆç‡ï¼ˆP/Eï¼‰ã€‚

å½“ç„¶è°ƒå’Œå¹³å‡æ•°è¿˜æœ‰å¾ˆå¤šåº”ç”¨åœºæ™¯ï¼Œæ¯”å¦‚ç»Ÿè®¡å­¦ä¸Šçš„F1è¯„åˆ†ï¼Œå°±æ˜¯å‡†ç¡®ç‡å’Œå¬å›çš„è°ƒå’Œå¹³å‡æ•°ã€‚

å› ä¸ºæ˜¯å¯¼æ•°ï¼Œæ‰€ä»¥æ˜¯æŒ‡æ•°ï¼Œä»æŒ‡æ•°åˆ†å¸ƒçš„å˜åŒ–ç‡æ¥çœ‹ï¼Œè°ƒå’Œå¹³å‡æ›´é‡è§†è¾ƒå°å€¼ï¼šè¾ƒå°å€¼çš„å˜åŒ–å¯¹è°ƒå’Œå¹³å‡çš„å½±å“å¤§äºè¾ƒå¤§å€¼çš„å˜åŒ–ã€‚
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºCSDNåšä¸»ã€Œstray_worldã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚
åŸæ–‡é“¾æ¥ï¼šhttps://blog.csdn.net/stray_world/article/details/104323693

:::

---

![](https://drhuyue.site:10002/sammo3182/figure/prob_means.jpg){fig-align="center" height=num}


# Types of Distribution

## Distribution: Types and Examples


:::: {.columns}

::: {.column width="50%"}

*Discrete*

:::{.r-vstack}
![Jacob Bernoulli (1654--1705)](https://drhuyue.site:10002/sammo3182/figure/dist_Jakob_Bernoulli.jpg){height=200}

![SimÃ©on Poisson (1781--1804)](https://drhuyue.site:10002/sammo3182/figure/dist_Poisson.jpg){height=200}
:::

:::

::: {.column width="50%"}

*Continuous*

:::{.r-vstack}
![Gerolamo Cardano (1501--1576)](https://drhuyue.site:10002/sammo3182/figure/dist_Cardano.jpg){height=200}

![Clarl F. Gauss (1777--1855)](https://drhuyue.site:10002/sammo3182/figure/dist_Gauss.jpg){height=200}
:::

:::

::::


:::{.notes}

*Discrete*

+ Binomial: Bernoulli is discovered by Jacob, who also invented mathematical constant e.
+ Poisson

*Continuous*

+ Uniform: Cardano defined uniform in the 16th century, "æ„å¤§åˆ©æ–‡è‰ºå¤å…´æ—¶æœŸç™¾ç§‘å…¨ä¹¦å¼çš„å­¦è€…ï¼Œ æ•°å­¦å®¶ã€ç‰©ç†å­¦å®¶ã€å æ˜Ÿå®¶ã€å“²å­¦å®¶å’ŒèµŒå¾’ï¼Œå¤å…¸æ¦‚ç‡è®ºåˆ›å§‹äºº"
+ Normal
    - ä¸˜æˆæ¡(1949)è¢«èª‰ä¸º[æ•°å­¦çš‡å¸]{https://www.nytimes.com/2006/10/17/science/17yau.html}ï¼Œé«˜æ–¯(1777)è¢«èª‰ä¸ºæ•°å­¦ç‹å­, è¯´é«˜æ–¯æ˜¯æ•°å­¦ç‹å­ï¼Œæ„æ€ä¸æ˜¯é«˜æ–¯ä¹‹ä¸Šè¿˜æœ‰è¿™ä¸ªç‹é‚£ä¸ªç‹ï¼Œè€Œæ˜¯æŠŠæ•°å­¦æ¯”ä½œç‹ã€‚æ•°å­¦æ˜¯ç‹ï¼Œé«˜æ–¯æ˜¯ç‹å­.

:::


## Bernoulli

:::{style="text-align: center"}
*Throwing a fair coin*
:::

:::{.fragment}
Bernoulli: Let $k\in 0, 1,$ p is P(X = 1)
:::

:::{.fragment}
CDF: 
$$
F = \begin{cases}
0, if\ k<0,\\
1 - p, if\ k \in[0, 1),\\
1, if\ k \geq 1.
\end{cases}
$$
:::

::::{.columns}
:::{.column width="50%" .fragment}
PMF: 

$$f(k;p) = p^k(1 - p)^{1 - k}$$

+ &mu; = p
+ &sigma;<sup>2</sup> = p(1 - p)
:::

:::{.column width="50%" .fragment}
![](https://drhuyue.site:10002/sammo3182/figure/dist_bernoulli_pmf.gif){height=250}
:::
::::

:::{.notes}

why pmf? Discrete

There is only cdf, no cmf:

The proper terminology is Cumulative Distribution Function, (CDF). The CDF is defined as

$$F_X(x) = \mathrm{P}\{X \leq x\}.$$

With this definition, the nature of the random variable X is irrelevant: continuous, discrete, or hybrids all have the same definition. As you note, for a discrete random variable the CDF has a very different appearance than for a continuous random variable. In the first case, it is a step function; in the second it is a continuous function.
:::


## Binomial distribution

:::{style="text-align: center"}
*Throwing multiple fair coins*
:::

PDF: $f(k; n, p) = {n \choose k}p^k(1 - p)^{n - k}$ [*Why combination?*]{.green .fragment}

:::: {.columns}

::: {.column width="40%"}
+ n, number of trials; 
+ p, the success probability in each trial; 
+ k, the number of success
:::

::: {.column width="60%"}
- &mu; = np    
- &sigma;<sup>2</sup> = np(1 - p)

![](https://drhuyue.site:10002/sammo3182/figure/dist_binomial_pdf.png){.fragment fig-align="center" height=400}
:::

::::


:::{.notes}
Combination: no order, every draw is independent
:::

## Application

A university hired 100 graduate students per year, 25 female and 75 male. 
Given that the general hired ratio is 4:6 for women:men, what's the chance that the employment is gender discrimination free?

:::{.fragment}
Let's [assume]{.red} the employment of any student does not affect the chance of hiring others. [Why is this important?]{.green .fragment}
:::

:::{.fragment .fade-in-then-semi-out}
$$PDF = {n \choose r}\pi^r(1 - \pi)^{n - r}$$
:::

:::{.fragment}
$$P(25) = {100 \choose 25}0.4^{25}(1 - 0.4)^{75} = 0.0006.$$
:::

:::{.fragment style="text-align:center; margin-top: 2em"}
Implication:

*Very unlikely*.
:::


## Poisson Distribution

:::{style="text-align:center"}
PMF:
$Pr(X{=}k)= \frac{\lambda^k e^{-\lambda}}{k!},$

k is the number of occurrences

&mu; = &lambda;;    
&sigma;<sup>2</sup> = &lambda;.
:::

::::{.columns style="text-align:center; margin-top: 2em"}
:::{.column width="40%" .fragment}
![](https://drhuyue.site:10002/sammo3182/figure/dist_poisson.gif){height=400}
:::

:::{.column width="60%" .fragment .nonincremental}
*Application*

1. Number of Network Failures per Week
1. Number of Website Visitors per Hour
1. Number of Arrivals at a Restaurant
1. Number of Calls per Hour at a Call Center
1. Average Number of Storms in a City
1. Number of Emergency Calls Received by a Hospital Every Minute
:::
::::


## Uniform Distribution


::::{.columns style="text-align:center"}
:::{.column width="50%" .fragment}
CDF: 
$$F = \begin{cases}
0, if\ x < a,\\
\frac{x - a}{b - a}, if\ x \in[a, b),\\
1, if\ x \geq b.
\end{cases}$$

![](https://drhuyue.site:10002/sammo3182/figure/dist_uniform_cdf.png){height=350}
:::

:::{.column width="50%" .fragment}
PDF:

$$f(x) = \begin{cases} 1/(b - a), if\ x \in [a, b],\\ 0, otherwise.\end{cases}$$

![](https://drhuyue.site:10002/sammo3182/figure/dist_uniform_pdf.png){height=350}
:::
::::


## Moments of the Uniform Distribution

::::{.columns style="text-align:center"}
:::{.column width="40%" .fragment}
\begin{align}
\mu =& \int^b_a x \frac{1}{b - a} dx, \\
=& \frac{1}{b - a}\int^b_axdx, \\
=& \frac{1}{b - a}\frac{x^2}{2}|^b_a, \\
=& \frac{b^2 - a^2}{2(b - a)}, \\
=& \frac{a + b}{2}.
\end{align}
:::

:::{.notes}
\begin{align}
(b - a)^3 =& b^3 - 3b^2a + 3a^2b - 3a^3\\
\Rightarrow b^3 - a^3 =& (b - a)^3 + (3b^2a - 3a^2b),\\
=&(b - a)[(b - a)^2 + 3ba].\\

\therefore\frac{b^3 - a^3}{3(b - a)} - (\frac{a + b}{2})^2 =& \frac{(b - a)[(b - a)^2 + 3ba]}{3(b - a)} - \frac{(a + b)^2}{4},\\
=& \frac{4[(b - a)^2 + 3ba] - 3(a + b)^2}{12},\\
=& \frac{4b^2 + 4ab + 4a^2 - 3b^2 - 3a^2 - 6ab}{12},\\
=& \frac{b^2 - 2ab + a^2}{12} = \frac{(b - a)^2}{12}.
\end{align}
:::


:::{.column width="60%" .fragment}
\begin{align}
\sigma^2 =& \sum x^2p(x) - \mu^2, \\
=& \int^b_ax^2\frac{1}{b - a}dx - (\frac{a + b}{2})^2, \\
=& \frac{1}{b - a}\int^b_ax^2dx - (\frac{a + b}{2})^2,\\
=& \frac{1}{b - a}\frac{x^3}{3}|^b_a - (\frac{a + b}{2})^2,\\
=& \frac{b^3 - a^3}{3(b - a)} - (\frac{a + b}{2})^2 = \frac{(b - a)^2}{12}.
\end{align}
:::
::::

## Application of the Uniform Distribution

![](https://drhuyue.site:10002/sammo3182/figure/dist_lotteryGenerator.gif){height=200 fig-align="center"}

:::{.fragment style="text-align: center"}
Any type of random number generators.
:::

::::{.columns}
:::{.column width="50%" .fragment}
![](https://drhuyue.site:10002/sammo3182/figure/ci_fsmrof.png){height=30} Discrete uniform distribution

> The probability of occurrence of the events is [equally]{.red} likely and falls within a finite set of values

:::

:::{.column width="50%" .fragment}
E.g.: 

1. Guessing a birthday of a stranger
1. Raffle tickets
1. Lucky Draw Contest
1. Throwing a Dart
:::
::::


## Normal Distribution: Gaussian curve

PDF: 

$$f(x) = \varphi(\frac{x - \mu}{\sigma}) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x - \mu)^2}{2\sigma^2}}.$$

When &mu; = 0; &sigma;<sup>2</Sup> = 1, standard normal distribution.


::::{.columns style="text-align:center"}
:::{.column width="50%" .fragment style="margin-top: 2em"}
*Z Score:*

$Z = \frac{x - \mu}{\sigma}$ &larr; $f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(z)^2}{2}}$
:::

:::{.column width="50%" .fragment}
![](https://drhuyue.site:10002/sammo3182/figure/dist_zscoreNormal.gif){height=400 fig-align="center"}
:::
::::

:::{.notes}
Knowing Z-score, one can calculate the probability of it accordingly
:::

## Z to Probability

:::: {.columns}

::: {.column width="70%"}
Old days

![](https://drhuyue.site:10002/sammo3182/figure/dist_zScore.gif){.fragment height=400 fig-align="center"}
:::

::: {.column .fragment width="30%"}
Cool kids

`pnorm(<Z-score>)`
:::

::::


## Application

Given that the average IQ in the U.S. is 100 with a standard deviation of 16, what's the probability a US citizen's IQ is higher than 125 or lower than 85?

:::{.fragment style="text-align:center; margin-top: 2em"}
$Z_1 = \frac{125 - 100}{16} = 1.056$

$Z_2 = \frac{85 - 100}{16} = -0.9375$
:::

- P(X &ge; 125) = `1 - pnorm(1.056)` = `r 1 - pnorm(1.056)`
- P(X < 85) = `pnorm(-0.9375)` = `r pnorm(-0.9375)`

:::{.fragment style="text-align:center; margin-top: 2em"}
p-value: $P(z\leq x)$.

We'll talk about about that later.
:::


# Distribution &rarr; Prediction

## Meaning

*"What would you guess if asking you the chance of heads to toss a coin?"*

:::{.fragment style="text-align:center; margin-top: 2em"}
1. &mu; = E(X) = &sum; xp(x)
2. &sigma;<sup>2</sup> = E(x - &mu;)<sup>2</sup> = &sum; (x - &mu;)<sup>2</sup>p(x)
:::

:::{.fragment style="margin-top: 2em"}
*Rule of expectation*

- E(aX + bY + c) = aE(X) + bE(Y) + c;
- var(aX + bY) = a<sup>2</sup>var(x) + b<sup>2</sup>var(y) + 2ab&bull;cov(x, y)
:::

## Application

X is the reward generator of a paid module of a video game, the seed of which is based on tossing a fair dice (ğŸ˜‘).
When the dice is tossed, the reward is produced following this function: g(X) = 2 + 3X.
What's the expectation of rewards a whale can get by purchasing this module?

:::{.fragment style="margin-top: 2em"}
$$E(X) = \sum xp(x) = 1\times\frac{1}{6} + 2\times\frac{1}{6} +\dots+6\times\frac{1}{6} = 3.5.$$

Then $$E(g(x)) = E(2 + 3X) = 2 + 3\times 3.5 = 12.5.$$
:::


:::{.notes}
Whale: æ°ªé‡‘ç©å®¶
:::

## Take-home point

::: {style="text-align: center"}
![](https://drhuyue.site:10002/sammo3182/figure/dist_mindmap.png){height="600"}
:::

# Appendix

## Bonus: What's derivative

{{< video https://drhuyue.site:10002/sammo3182/video/dist_dervative.mp4 title="3Blue1Brown: What does derivative do" height=600 preload="auto" controls allowfullscreen>}}

## Want to watch more? {.nonincremental}

- [ã€Derivative formulas through geometryã€‘ https://www.bilibili.com/video/BV1wo4y1Q7uN/?share_source=copy_web](https://youtu.be/S0_qX4VJhMQ?si=McEJJ7xDpYsNu42e)
- [ã€Visualizing the chain rule and product ruleã€‘ https://www.bilibili.com/video/BV18v411n7Dn/?share_source=copy_web](https://youtu.be/YG15m2VwSjA?si=er1krY4mpnbt4RGb)


